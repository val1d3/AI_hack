import streamlit as st
import cv2
import easyocr
import pandas as pd
from ultralytics import YOLO
from supervision import LineZone, BoxAnnotator, LineZoneAnnotator, Detections
from supervision.geometry.core import Point
from datetime import datetime, timedelta
import tempfile
import numpy as np
from collections import OrderedDict
import os
import sqlite3
import json
from contextlib import contextmanager

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
st.title("üöâ –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ —Å –∂–µ–ª–µ–∑–Ω–æ–¥–æ—Ä–æ–∂–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã")
st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
db_enabled = st.sidebar.checkbox("–°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö", value=True)
db_path = st.sidebar.text_input("–ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö", "platform_analysis.db")

# ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–æ—Å—Ç–∞–≤—å—Ç–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
confidence = st.sidebar.slider("Confidence", 0.0, 1.0, 0.4)
line_y = st.sidebar.slider("–ü–æ–∑–∏—Ü–∏—è –ª–∏–Ω–∏–∏", 0, 1080, 600)
skip_frames = st.sidebar.slider("–ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –∫–∞–¥—Ä–æ–≤", 1, 10, 2)
resize_factor = st.sidebar.slider("–£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è", 0.3, 1.0, 0.6)
disable_ocr = st.sidebar.checkbox("–û—Ç–∫–ª—é—á–∏—Ç—å OCR (—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏)", value=False)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–ª–∞—Å—Ç–∏ OCR
ocr_x = st.sidebar.slider("X-–ø–æ–∑–∏—Ü–∏—è OCR", 0, 1000, 10)
ocr_y = st.sidebar.slider("Y-–ø–æ–∑–∏—Ü–∏—è OCR", 0, 1000, 10)
ocr_width = st.sidebar.slider("–®–∏—Ä–∏–Ω–∞ OCR", 100, 800, 300)
ocr_height = st.sidebar.slider("–í—ã—Å–æ—Ç–∞ OCR", 20, 200, 50)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–æ–Ω—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–µ–∑–¥–∞
st.sidebar.subheader("–ó–æ–Ω–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–µ–∑–¥–∞")
train_zone_x = st.sidebar.slider("–ù–∞—á–∞–ª–æ –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞ (X)", 0, 1000, 500)
train_zone_width = st.sidebar.slider("–®–∏—Ä–∏–Ω–∞ –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞", 100, 1000, 500)
train_zone_y = st.sidebar.slider("–ù–∞—á–∞–ª–æ –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞ (Y)", 0, 800, 200)
train_zone_height = st.sidebar.slider("–í—ã—Å–æ—Ç–∞ –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞", 100, 1000, 400)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ü–≤–µ—Ç–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–µ–∑–¥–∞
st.sidebar.subheader("–¶–≤–µ—Ç–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ–µ–∑–¥–∞")
gray_lower = st.sidebar.slider("–°–µ—Ä—ã–π –Ω–∏–∂–Ω–∏–π –ø–æ—Ä–æ–≥", 0, 255, 50)
gray_upper = st.sidebar.slider("–°–µ—Ä—ã–π –≤–µ—Ä—Ö–Ω–∏–π –ø–æ—Ä–æ–≥", 0, 255, 200)
orange_lower_h = st.sidebar.slider("–û—Ä–∞–Ω–∂–µ–≤—ã–π H –Ω–∏–∂–Ω–∏–π", 0, 180, 5)
orange_upper_h = st.sidebar.slider("–û—Ä–∞–Ω–∂–µ–≤—ã–π H –≤–µ—Ä—Ö–Ω–∏–π", 0, 180, 15)
red_lower_h1 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H1 –Ω–∏–∂–Ω–∏–π", 0, 180, 0)
red_upper_h1 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H1 –≤–µ—Ä—Ö–Ω–∏–π", 0, 180, 10)
red_lower_h2 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H2 –Ω–∏–∂–Ω–∏–π", 0, 180, 170)
red_upper_h2 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H2 –≤–µ—Ä—Ö–Ω–∏–π", 0, 180, 180)

# ‚úÖ –£–ü–†–û–©–ï–ù–ù–´–ô ReID –Ω–∞ –æ—Å–Ω–æ–≤–µ OpenCV
st.sidebar.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ ReID")
reid_threshold = st.sidebar.slider("–ü–æ—Ä–æ–≥ ReID —Å—Ö–æ–¥—Å—Ç–≤–∞", 0.1, 1.0, 0.6)
enable_reid = st.sidebar.checkbox("–í–∫–ª—é—á–∏—Ç—å ReID", value=True)

# --- –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö ---
@contextmanager
def get_db_connection():
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î"""
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()

def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    with get_db_connection() as conn:
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ
        conn.execute('''
            CREATE TABLE IF NOT EXISTS videos (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT NOT NULL,
                processed_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                frame_count INTEGER,
                processed_frames INTEGER,
                duration_seconds REAL,
                resolution TEXT,
                fps REAL
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –æ –ª—é–¥—è—Ö
        conn.execute('''
            CREATE TABLE IF NOT EXISTS people (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                person_id INTEGER NOT NULL,
                appearance_time TEXT NOT NULL,
                disappearance_time TEXT,
                waiting_minutes REAL,
                reid_enabled BOOLEAN,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å–æ–±—ã—Ç–∏–π –ø–æ–µ–∑–¥–æ–≤
        conn.execute('''
            CREATE TABLE IF NOT EXISTS train_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                arrival_time TEXT NOT NULL,
                departure_time TEXT,
                duration_seconds REAL,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        conn.execute('''
            CREATE TABLE IF NOT EXISTS occupancy (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                timestamp TEXT NOT NULL,
                people_count INTEGER NOT NULL,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ü–≤–µ—Ç–æ–≤ –ø–æ–µ–∑–¥–∞
        conn.execute('''
            CREATE TABLE IF NOT EXISTS color_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                frame_index INTEGER NOT NULL,
                gray_percent REAL,
                orange_percent REAL,
                red_percent REAL,
                combined_percent REAL,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞
        conn.execute('''
            CREATE TABLE IF NOT EXISTS line_statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                in_count INTEGER DEFAULT 0,
                out_count INTEGER DEFAULT 0,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        conn.execute('''
            CREATE TABLE IF NOT EXISTS processing_settings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                settings_json TEXT NOT NULL,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        conn.commit()

def save_video_info(conn, video_info):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ"""
    cursor = conn.execute('''
        INSERT INTO videos (filename, frame_count, processed_frames, duration_seconds, resolution, fps)
        VALUES (?, ?, ?, ?, ?, ?)
    ''', (
        video_info['filename'],
        video_info['frame_count'],
        video_info['processed_frames'],
        video_info['duration_seconds'],
        video_info['resolution'],
        video_info['fps']
    ))
    return cursor.lastrowid

def save_people_data(conn, video_id, people_data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ª—é–¥—è—Ö"""
    for person in people_data:
        waiting_minutes = None
        if person["–û–∂–∏–¥–∞–Ω–∏–µ"] != "-":
            try:
                waiting_minutes = float(person["–û–∂–∏–¥–∞–Ω–∏–µ"].replace(" –º–∏–Ω", ""))
            except:
                waiting_minutes = 0.0
        
        conn.execute('''
            INSERT INTO people (video_id, person_id, appearance_time, disappearance_time, waiting_minutes, reid_enabled)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            video_id,
            person["ID"],
            person["–ü–æ—è–≤–ª–µ–Ω–∏–µ"],
            person["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] if person["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] != "-" else None,
            waiting_minutes,
            person["ReID"] == "‚úì"
        ))

def save_train_events(conn, video_id, train_events):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–±—ã—Ç–∏—è –ø–æ–µ–∑–¥–æ–≤"""
    for event in train_events:
        duration = None
        if event["–ü—Ä–∏–±—ã—Ç–∏–µ"] and event["–£–±—ã—Ç–∏–µ"]:
            try:
                t1 = datetime.strptime(event["–ü—Ä–∏–±—ã—Ç–∏–µ"], "%H:%M:%S")
                t2 = datetime.strptime(event["–£–±—ã—Ç–∏–µ"], "%H:%M:%S")
                duration = (t2 - t1).total_seconds()
            except:
                duration = None
        
        conn.execute('''
            INSERT INTO train_events (video_id, arrival_time, departure_time, duration_seconds)
            VALUES (?, ?, ?, ?)
        ''', (video_id, event["–ü—Ä–∏–±—ã—Ç–∏–µ"], event["–£–±—ã—Ç–∏–µ"], duration))

def save_occupancy(conn, video_id, occupancy):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏"""
    for occ in occupancy:
        conn.execute('''
            INSERT INTO occupancy (video_id, timestamp, people_count)
            VALUES (?, ?, ?)
        ''', (video_id, occ["time"], occ["people"]))

def save_color_analysis(conn, video_id, color_analysis):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤"""
    for color_data in color_analysis:
        conn.execute('''
            INSERT INTO color_analysis (video_id, frame_index, gray_percent, orange_percent, red_percent, combined_percent)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            video_id,
            color_data["frame"],
            color_data["gray"],
            color_data["orange"],
            color_data["red"],
            color_data["combined"]
        ))

def save_line_statistics(conn, video_id, in_count, out_count):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ª–∏–Ω–∏–∏"""
    conn.execute('''
        INSERT INTO line_statistics (video_id, in_count, out_count)
        VALUES (?, ?, ?)
    ''', (video_id, in_count, out_count))

def save_processing_settings(conn, video_id, settings):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    conn.execute('''
        INSERT INTO processing_settings (video_id, settings_json)
        VALUES (?, ?)
    ''', (video_id, json.dumps(settings)))

def load_previous_analyses():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∞–Ω–∞–ª–∏–∑–æ–≤"""
    if not os.path.exists(db_path):
        return []
    
    try:
        with get_db_connection() as conn:
            cursor = conn.execute('''
                SELECT id, filename, processed_date, frame_count, processed_frames 
                FROM videos 
                ORDER BY processed_date DESC
            ''')
            return cursor.fetchall()
    except:
        return []

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
if db_enabled:
    init_database()

# ... –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ (–º–æ–¥–µ–ª–∏, —Ä–∏–¥–µ—Ä—ã, —Ö—Ä–∞–Ω–∏–ª–∏—â–∞) –æ—Å—Ç–∞–≤—å—Ç–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ...
model = YOLO("yolov8n.pt")

# OCR —Ä–∏–¥–µ—Ä
reader = None
if not disable_ocr:
    try:
        reader = easyocr.Reader(['en'], gpu=False)
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å OCR: {e}")
        reader = None

# –ê–Ω–Ω–æ—Ç–∞—Ç–æ—Ä—ã
box_annotator = BoxAnnotator()
line_annotator = LineZoneAnnotator()
line = LineZone(start=Point(0, line_y), end=Point(9999, line_y))

# –•—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–∞–Ω–Ω—ã—Ö
people_data = []
train_events = []
occupancy = []

# ‚úÖ –£–ü–†–û–©–ï–ù–ù–´–ô ReID –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º –∏ ORB features
class SimpleReIDStorage:
    def __init__(self, similarity_threshold=0.6):
        self.similarity_threshold = similarity_threshold
        self.known_descriptors = OrderedDict()  # ID -> ORB descriptors
        self.known_histograms = OrderedDict()   # ID -> —Ü–≤–µ—Ç–æ–≤—ã–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        self.orb = cv2.ORB_create()
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        
    def extract_features(self, image, bbox):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞"""
        try:
            # –í—ã—Ä–µ–∑–∞–µ–º –æ–±–ª–∞—Å—Ç—å —á–µ–ª–æ–≤–µ–∫–∞
            x1, y1, x2, y2 = [int(coord) for coord in bbox]
            person_crop = image[y1:y2, x1:x2]
            
            if person_crop.size == 0:
                return None, None
                
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            lab = cv2.cvtColor(person_crop, cv2.COLOR_BGR2LAB)
            lab[:,:,0] = cv2.createCLAHE(clipLimit=2.0).apply(lab[:,:,0])
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ORB –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã
            gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)
            keypoints, descriptors = self.orb.detectAndCompute(gray, None)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—ã–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
            hsv = cv2.cvtColor(enhanced, cv2.COLOR_BGR2HSV)
            hist_h = cv2.calcHist([hsv], [0], None, [8], [0, 180])
            hist_s = cv2.calcHist([hsv], [1], None, [8], [0, 256])
            hist_v = cv2.calcHist([hsv], [2], None, [8], [0, 256])
            
            hist_h = cv2.normalize(hist_h, hist_h).flatten()
            hist_s = cv2.normalize(hist_s, hist_s).flatten()
            hist_v = cv2.normalize(hist_v, hist_v).flatten()
            histogram = np.concatenate([hist_h, hist_s, hist_v])
            
            return descriptors, histogram
        except Exception as e:
            return None, None
    
    def calculate_similarity(self, desc1, hist1, desc2, hist2):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–±–æ—Ä–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        similarity = 0.0
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã (70% –≤–µ—Å–∞)
        if hist1 is not None and hist2 is not None:
            hist_sim = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            similarity += hist_sim * 0.7
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º ORB –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã (30% –≤–µ—Å–∞)
        if desc1 is not None and desc2 is not None and len(desc1) > 0 and len(desc2) > 0:
            try:
                matches = self.bf.match(desc1, desc2)
                if len(matches) > 0:
                    orb_sim = len(matches) / min(len(desc1), len(desc2))
                    similarity += min(orb_sim, 1.0) * 0.3
            except:
                pass
        
        return similarity
    
    def find_best_match(self, new_descriptors, new_histogram):
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        if not self.known_descriptors:
            return None, 0.0
            
        best_match_id = None
        best_similarity = 0.0
        
        for person_id in self.known_descriptors:
            stored_desc, stored_hist = self.known_descriptors[person_id], self.known_histograms[person_id]
            similarity = self.calculate_similarity(new_descriptors, new_histogram, stored_desc, stored_hist)
            
            if similarity > best_similarity and similarity > self.similarity_threshold:
                best_similarity = similarity
                best_match_id = person_id
                
        return best_match_id, best_similarity
    
    def add_person(self, person_id, descriptors, histogram):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        self.known_descriptors[person_id] = descriptors
        self.known_histograms[person_id] = histogram
    
    def update_person(self, person_id, descriptors, histogram):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞"""
        if person_id in self.known_descriptors:
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–µ)
            old_desc = self.known_descriptors[person_id]
            if descriptors is not None and len(descriptors) > len(old_desc):
                self.known_descriptors[person_id] = descriptors
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É (—Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ)
            old_hist = self.known_histograms[person_id]
            alpha = 0.7
            new_hist = alpha * old_hist + (1 - alpha) * histogram
            self.known_histograms[person_id] = new_hist
        else:
            self.add_person(person_id, descriptors, histogram)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ ReID
reid_storage = SimpleReIDStorage(similarity_threshold=reid_threshold) if enable_reid else None

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ü–≤–µ—Ç–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
def detect_train_colors(roi):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ü–≤–µ—Ç–æ–≤ –ø–æ–µ–∑–¥–∞ –≤ –æ–±–ª–∞—Å—Ç–∏"""
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    
    gray_mask = cv2.inRange(roi, (gray_lower, gray_lower, gray_lower), (gray_upper, gray_upper, gray_upper))
    
    lower_orange = np.array([orange_lower_h, 100, 100])
    upper_orange = np.array([orange_upper_h, 255, 255])
    orange_mask = cv2.inRange(hsv, lower_orange, upper_orange)
    
    lower_red1 = np.array([red_lower_h1, 100, 100])
    upper_red1 = np.array([red_upper_h1, 255, 255])
    lower_red2 = np.array([red_lower_h2, 100, 100])
    upper_red2 = np.array([red_upper_h2, 255, 255])
    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    red_mask = cv2.bitwise_or(red_mask1, red_mask2)
    
    combined_mask = cv2.bitwise_or(gray_mask, orange_mask)
    combined_mask = cv2.bitwise_or(combined_mask, red_mask)
    
    total_pixels = roi.shape[0] * roi.shape[1]
    if total_pixels == 0:
        return 0, 0, 0, 0
    
    gray_percent = np.sum(gray_mask > 0) / total_pixels * 100
    orange_percent = np.sum(orange_mask > 0) / total_pixels * 100
    red_percent = np.sum(red_mask > 0) / total_pixels * 100
    combined_percent = np.sum(combined_mask > 0) / total_pixels * 100
    
    return gray_percent, orange_percent, red_percent, combined_percent

def is_in_train_zone(x1, y1, x2, y2, frame_width, frame_height):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –æ–±—ä–µ–∫—Ç –≤ –∑–æ–Ω–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–µ–∑–¥–∞"""
    zone_x1 = train_zone_x
    zone_x2 = min(frame_width, train_zone_x + train_zone_width)
    zone_y1 = train_zone_y
    zone_y2 = min(frame_height, train_zone_y + train_zone_height)
    
    center_x = (x1 + x2) / 2
    center_y = (y1 + y2) / 2
    
    in_zone = (zone_x1 <= center_x <= zone_x2) and (zone_y1 <= center_y <= zone_y2)
    
    overlap_x = max(0, min(x2, zone_x2) - max(x1, zone_x1))
    overlap_y = max(0, min(y2, zone_y2) - max(y1, zone_y1))
    overlap_area = overlap_x * overlap_y
    object_area = (x2 - x1) * (y2 - y1)
    
    if object_area > 0:
        overlap_ratio = overlap_area / object_area
    else:
        overlap_ratio = 0
    
    return in_zone or overlap_ratio > 0.3, (zone_x1, zone_y1, zone_x2, zone_y2)

# --- –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö ---
st.sidebar.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏")

if db_enabled:
    # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∞–Ω–∞–ª–∏–∑—ã
    previous_analyses = load_previous_analyses()
    if previous_analyses:
        st.sidebar.subheader("–ü—Ä–µ–¥—ã–¥—É—â–∏–µ –∞–Ω–∞–ª–∏–∑—ã")
        for analysis in previous_analyses:
            st.sidebar.write(f"{analysis['filename']} - {analysis['processed_date']}")

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏ –≤–∏–¥–µ–æ —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã", type=["mp4", "avi", "mov"])

if uploaded_file:
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    processing_settings = {
        "confidence": confidence,
        "line_y": line_y,
        "skip_frames": skip_frames,
        "resize_factor": resize_factor,
        "disable_ocr": disable_ocr,
        "ocr_x": ocr_x,
        "ocr_y": ocr_y,
        "ocr_width": ocr_width,
        "ocr_height": ocr_height,
        "train_zone_x": train_zone_x,
        "train_zone_width": train_zone_width,
        "train_zone_y": train_zone_y,
        "train_zone_height": train_zone_height,
        "reid_threshold": reid_threshold,
        "enable_reid": enable_reid
    }
    
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    video_path = tfile.name

    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    original_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps if fps > 0 else 0
    
    process_w = int(original_w * resize_factor)
    process_h = int(original_h * resize_factor)

    stframe = st.empty()
    progress = st.progress(0)

    # –î–ª—è –ø–æ–µ–∑–¥–∞
    train_present = False
    train_arrival_time = None
    tracked_ids = set()
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ —Å—Ç–∞—Ä—ã—Ö ID –∫ –Ω–æ–≤—ã–º —á–µ—Ä–µ–∑ ReID
    id_mapping = {}  # –Ω–æ–≤—ã–π_tracker_id -> —Å—Ç–∞—Ä—ã–π_person_id
    next_person_id = 1
    
    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ü–≤–µ—Ç–æ–≤
    color_analysis_data = []

    frame_idx = 0
    processed_frames = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –∫–∞–¥—Ä—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        if frame_idx % skip_frames != 0:
            frame_idx += 1
            continue

        # –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if resize_factor < 1.0:
            process_frame = cv2.resize(frame, (process_w, process_h))
        else:
            process_frame = frame

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
        timestamp_str = "00:00:00"
        current_dt = datetime.now()
        
        if not disable_ocr and reader is not None:
            try:
                y1 = max(0, min(ocr_y, frame.shape[0] - ocr_height))
                y2 = min(frame.shape[0], y1 + ocr_height)
                x1 = max(0, min(ocr_x, frame.shape[1] - ocr_width))
                x2 = min(frame.shape[1], x1 + ocr_width)
                
                crop = frame[y1:y2, x1:x2]
                gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
                enhanced = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)
                blurred = cv2.GaussianBlur(enhanced, (3, 3), 0)
                
                result = reader.readtext(blurred, detail=0, paragraph=True)
                
                if result:
                    timestamp_str = result[0]
                    time_formats = ["%H:%M:%S", "%H:%M", "%I:%M:%S %p", "%I:%M %p"]
                    
                    for fmt in time_formats:
                        try:
                            current_time = datetime.strptime(timestamp_str, fmt).time()
                            current_dt = datetime.combine(datetime.today(), current_time)
                            break
                        except:
                            continue
                            
            except Exception as e:
                st.sidebar.warning(f"–û—à–∏–±–∫–∞ OCR: {e}")

        # –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
        results = model.track(process_frame, persist=True, conf=confidence, 
                            classes=[0, 2, 3, 5, 6, 7], tracker="bytetrack.yaml", verbose=False)[0]
        
        # –°–æ–∑–¥–∞–µ–º Detections –æ–±—ä–µ–∫—Ç
        if results.boxes.id is not None:
            boxes = results.boxes.xyxy.cpu().numpy()
            confidence_scores = results.boxes.conf.cpu().numpy()
            class_ids = results.boxes.cls.cpu().numpy().astype(int)
            tracker_ids = results.boxes.id.cpu().numpy().astype(int)
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
            if resize_factor < 1.0:
                boxes = boxes / resize_factor
            
            detections = Detections(
                xyxy=boxes,
                confidence=confidence_scores,
                class_id=class_ids,
                tracker_id=tracker_ids
            )
            
            tracks = tracker_ids
        else:
            detections = Detections(
                xyxy=np.empty((0, 4)),
                confidence=np.array([]),
                class_id=np.array([], dtype=int)
            )
            tracks = None

        # –£–ü–†–û–©–ï–ù–ù–´–ô ReID –ª–æ–≥–∏–∫–∞ –¥–ª—è –ª—é–¥–µ–π
        current_people_tracks = []
        reid_matches = {}
        
        if enable_reid and reid_storage is not None and tracks is not None:
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª—é–¥–µ–π
            people_indices = np.where(detections.class_id == 0)[0]
            
            for idx in people_indices:
                tracker_id = int(tracks[idx])
                bbox = detections.xyxy[idx]
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
                descriptors, histogram = reid_storage.extract_features(frame, bbox)
                
                if descriptors is not None or histogram is not None:
                    # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ª—é–¥—è—Ö
                    matched_id, similarity = reid_storage.find_best_match(descriptors, histogram)
                    
                    if matched_id is not None and similarity > reid_threshold:
                        # –ù–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π ID
                        reid_matches[tracker_id] = matched_id
                        reid_storage.update_person(matched_id, descriptors, histogram)
                        current_people_tracks.append(matched_id)
                    else:
                        # –ù–æ–≤—ã–π —á–µ–ª–æ–≤–µ–∫ –∏–ª–∏ –Ω–µ—Ç —Ö–æ—Ä–æ—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                        if tracker_id not in id_mapping:
                            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π ID
                            new_person_id = next_person_id
                            next_person_id += 1
                            id_mapping[tracker_id] = new_person_id
                            reid_storage.add_person(new_person_id, descriptors, histogram)
                            current_people_tracks.append(new_person_id)
                        else:
                            # –£–∂–µ –µ—Å—Ç—å –º–∞–ø–ø–∏–Ω–≥
                            current_people_tracks.append(id_mapping[tracker_id])
                else:
                    # –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º tracker_id
                    if tracker_id not in id_mapping:
                        new_person_id = next_person_id
                        next_person_id += 1
                        id_mapping[tracker_id] = new_person_id
                    current_people_tracks.append(id_mapping[tracker_id])
        
        # –¢–µ–∫—É—â–µ–µ –∫–æ–ª-–≤–æ –ª—é–¥–µ–π
        people_count = np.sum(detections.class_id == 0) if len(detections) > 0 else 0
        occupancy.append({"time": current_dt.strftime("%H:%M:%S"), "people": people_count})

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ª—é–¥–µ–π —Å —É—á–µ—Ç–æ–º ReID
        if tracks is not None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º ReID ID –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã, –∏–Ω–∞—á–µ tracker_id
            if enable_reid and current_people_tracks:
                current_ids = set(current_people_tracks)
            else:
                current_ids = set(tracks[detections.class_id == 0])
            
            appeared = current_ids - tracked_ids
            disappeared = tracked_ids - current_ids

            for person_id in appeared:
                people_data.append({
                    "ID": int(person_id), 
                    "–ü–æ—è–≤–ª–µ–Ω–∏–µ": current_dt.strftime("%H:%M:%S"), 
                    "–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ": "-", 
                    "–û–∂–∏–¥–∞–Ω–∏–µ": "-",
                    "ReID": "‚úì" if enable_reid else "‚úó"
                })
            
            for person_id in disappeared:
                for row in people_data:
                    if row["ID"] == int(person_id) and row["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] == "-":
                        row["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] = current_dt.strftime("%H:%M:%S")
                        try:
                            t1 = datetime.strptime(row["–ü–æ—è–≤–ª–µ–Ω–∏–µ"], "%H:%M:%S")
                            t2 = datetime.strptime(row["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"], "%H:%M:%S")
                            wait = (t2 - t1).total_seconds() / 60
                            row["–û–∂–∏–¥–∞–Ω–∏–µ"] = f"{wait:.1f} –º–∏–Ω"
                        except:
                            row["–û–∂–∏–¥–∞–Ω–∏–µ"] = "0.0 –º–∏–Ω"

            tracked_ids = current_ids

        # –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–µ–∑–¥–æ–≤ –¢–û–õ–¨–ö–û –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∑–æ–Ω–µ
        train_detected = False
        best_train_confidence = 0
        best_train_info = ""
        
        if len(detections) > 0:
            potential_train_indices = np.where((detections.class_id == 6) |  # train
                                             ((detections.class_id == 5) & (detections.confidence > 0.6)) |  # bus
                                             ((detections.class_id == 7) & (detections.confidence > 0.6)))[0]  # truck
            
            for idx in potential_train_indices:
                x1, y1, x2, y2 = detections.xyxy[idx].astype(int)
                width = x2 - x1
                height = y2 - y1
                
                in_train_zone, zone_coords = is_in_train_zone(x1, y1, x2, y2, original_w, original_h)
                
                if not in_train_zone:
                    continue
                
                if width > original_w * 0.25 and height > original_h * 0.15:
                    x1_clip = max(0, x1)
                    y1_clip = max(0, y1)
                    x2_clip = min(original_w, x2)
                    y2_clip = min(original_h, y2)
                    
                    roi = frame[y1_clip:y2_clip, x1_clip:x2_clip]
                    
                    if roi.size > 0:
                        gray_percent, orange_percent, red_percent, combined_percent = detect_train_colors(roi)
                        
                        color_analysis_data.append({
                            "frame": frame_idx,
                            "gray": gray_percent,
                            "orange": orange_percent,
                            "red": red_percent,
                            "combined": combined_percent
                        })
                        
                        is_train_by_color = (
                            (gray_percent > 10) or
                            (orange_percent > 5) or
                            (red_percent > 5) or
                            (combined_percent > 15)
                        )
                        
                        detection_confidence = detections.confidence[idx]
                        combined_confidence = detection_confidence * 0.7 + (combined_percent / 100) * 0.3
                        
                        if is_train_by_color and combined_confidence > 0.5:
                            if combined_confidence > best_train_confidence:
                                best_train_confidence = combined_confidence
                                best_train_info = f"G:{gray_percent:.1f}% O:{orange_percent:.1f}% R:{red_percent:.1f}%"
                            train_detected = True

        if train_detected and not train_present:
            train_arrival_time = current_dt.strftime("%H:%M:%S")
            train_present = True
            st.sidebar.success(f"üöÇ –ü–æ–µ–∑–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –≤ {train_arrival_time}")
            st.sidebar.info(f"–¶–≤–µ—Ç–∞: {best_train_info}")
        elif not train_detected and train_present:
            train_events.append({
                "–ü—Ä–∏–±—ã—Ç–∏–µ": train_arrival_time, 
                "–£–±—ã—Ç–∏–µ": current_dt.strftime("%H:%M:%S")
            })
            train_present = False
            st.sidebar.info(f"–ü–æ–µ–∑–¥ —É–µ—Ö–∞–ª –≤ {current_dt.strftime('%H:%M:%S')}")

        # –õ–∏–Ω–∏—è –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞
        line.trigger(detections=detections)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞ –Ω–∞ –∫–∞–¥—Ä–µ
        zone_x1, zone_y1, zone_x2, zone_y2 = is_in_train_zone(0, 0, 0, 0, original_w, original_h)[1]
        cv2.rectangle(frame, (zone_x1, zone_y1), (zone_x2, zone_y2), (0, 255, 255), 2)
        cv2.putText(frame, "TRAIN ZONE", (zone_x1, zone_y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        frame = box_annotator.annotate(scene=frame, detections=detections)
        frame = line_annotator.annotate(frame, line)

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ ID —Å —É—á–µ—Ç–æ–º ReID
        if detections.tracker_id is not None:
            for i, (x1, y1, x2, y2) in enumerate(detections.xyxy):
                class_id = detections.class_id[i]
                tracker_id = int(detections.tracker_id[i]) if detections.tracker_id is not None else 0
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                if class_id == 0 and enable_reid:  # –ß–µ–ª–æ–≤–µ–∫ —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º ReID
                    display_id = id_mapping.get(tracker_id, tracker_id)
                    id_text = f"Person {display_id}"
                    color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π –¥–ª—è –ª—é–¥–µ–π —Å ReID
                elif class_id == 0:  # –ß–µ–ª–æ–≤–µ–∫ –±–µ–∑ ReID
                    display_id = tracker_id
                    id_text = f"Person {display_id}"
                    color = (255, 255, 255)  # –ë–µ–ª—ã–π –¥–ª—è –ª—é–¥–µ–π –±–µ–∑ ReID
                elif class_id == 6:  # –ü–æ–µ–∑–¥
                    class_names = {0: "Person", 2: "Car", 3: "Motorcycle", 5: "Bus", 6: "Train", 7: "Truck"}
                    class_name = class_names.get(class_id, "Unknown")
                    id_text = f"{class_name} {tracker_id}"
                    color = (0, 255, 255)  # –ñ–µ–ª—Ç—ã–π –¥–ª—è –ø–æ–µ–∑–¥–æ–≤
                else:
                    class_names = {0: "Person", 2: "Car", 3: "Motorcycle", 5: "Bus", 6: "Train", 7: "Truck"}
                    class_name = class_names.get(class_id, "Unknown")
                    id_text = f"{class_name} {tracker_id}"
                    color = (255, 255, 255)  # –ë–µ–ª—ã–π –¥–ª—è –¥—Ä—É–≥–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                
                cv2.putText(frame, id_text, 
                           (int(x1), int(y1) - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 
                           0.5, color, 2)

        # –ù–∞–¥–ø–∏—Å—å –≤—Ä–µ–º–µ–Ω–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        cv2.putText(frame, f"Time: {timestamp_str}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"People: {people_count}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"Train: {'Yes' if train_present else 'No'}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"ReID: {'ON' if enable_reid else 'OFF'}", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        if train_detected:
            cv2.putText(frame, f"Train Colors: {best_train_info}", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

        stframe.image(frame, channels="BGR")
        progress.progress(min(frame_idx / frame_count, 1.0))
        frame_idx += 1
        processed_frames += 1

    cap.release()

    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö ===
    if db_enabled:
        try:
            with get_db_connection() as conn:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
                video_info = {
                    'filename': uploaded_file.name,
                    'frame_count': frame_count,
                    'processed_frames': processed_frames,
                    'duration_seconds': duration,
                    'resolution': f"{original_w}x{original_h}",
                    'fps': fps
                }
                
                video_id = save_video_info(conn, video_info)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
                save_people_data(conn, video_id, people_data)
                save_train_events(conn, video_id, train_events)
                save_occupancy(conn, video_id, occupancy)
                save_color_analysis(conn, video_id, color_analysis_data)
                save_line_statistics(conn, video_id, line.in_count, line.out_count)
                save_processing_settings(conn, video_id, processing_settings)
                
                conn.commit()
                
                st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (ID: {video_id})")
                
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö: {e}")

    # === –î–∞—à–±–æ—Ä–¥ ===
    st.success(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_frames} –∫–∞–¥—Ä–æ–≤ –∏–∑ {frame_count}")

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("üìä –õ—é–¥–∏ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ")
        if people_data:
            df_people = pd.DataFrame(people_data)
            st.dataframe(df_people)
            csv_people = df_people.to_csv(index=False).encode()
            st.download_button("–°–∫–∞—á–∞—Ç—å CSV –ª—é–¥–µ–π", csv_people, "people.csv")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ReID
            if enable_reid and reid_storage:
                st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ReID")
                reid_count = len(reid_storage.known_descriptors) if reid_storage else 0
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª—é–¥–µ–π (ReID)", reid_count)
        else:
            st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ª—é–¥—è—Ö")

    with col2:
        st.subheader("üöÇ –ü–æ–µ–∑–¥–∞")
        if train_events:
            df_train = pd.DataFrame(train_events)
            st.dataframe(df_train)
            csv_train = df_train.to_csv(index=False).encode()
            st.download_button("–°–∫–∞—á–∞—Ç—å CSV –ø–æ–µ–∑–¥–æ–≤", csv_train, "trains.csv")
        else:
            st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–µ–∑–¥–∞—Ö")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ü–≤–µ—Ç–æ–≤
    if color_analysis_data:
        st.subheader("üé® –ê–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤ –ø–æ–µ–∑–¥–∞")
        df_colors = pd.DataFrame(color_analysis_data)
        st.line_chart(df_colors[['gray', 'orange', 'red', 'combined']])

    st.subheader("üìà –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
    if occupancy:
        df_occ = pd.DataFrame(occupancy)
        st.line_chart(df_occ.set_index("time"))
    else:
        st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏")

    if people_data:
        try:
            wait_times = [float(row["–û–∂–∏–¥–∞–Ω–∏–µ"].replace(" –º–∏–Ω", "")) for row in people_data if row["–û–∂–∏–¥–∞–Ω–∏–µ"] != "-"]
            if wait_times:
                avg_wait = sum(wait_times) / len(wait_times)
                st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ–µ–∑–¥–∞", f"{avg_wait:.1f} –º–∏–Ω")
        except:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ–µ–∑–¥–∞", "–ù/–î")

    st.subheader("–í—Ö–æ–¥/–í—ã—Ö–æ–¥")
    st.write(f"–í–æ—à–ª–æ: {line.in_count}‚ÄÉ–í—ã—à–ª–æ: {line.out_count}")

# --- –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã ---
if db_enabled and os.path.exists(db_path):
    st.sidebar.header("–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î")
    
    if st.sidebar.button("–ü–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∞–Ω–∞–ª–∏–∑–æ–≤"):
        with get_db_connection() as conn:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ
            videos = conn.execute('''
                SELECT id, filename, processed_date, frame_count, processed_frames 
                FROM videos 
                ORDER BY processed_date DESC
            ''').fetchall()
            
            if videos:
                st.subheader("üìã –ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤ –≤–∏–¥–µ–æ")
                for video in videos:
                    with st.expander(f"{video['filename']} - {video['processed_date']}"):
                        st.write(f"ID: {video['id']}")
                        st.write(f"–ö–∞–¥—Ä–æ–≤: {video['frame_count']} (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {video['processed_frames']})")
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ª—é–¥—è–º
                        people_stats = conn.execute(
                            'SELECT COUNT(*) as total_people FROM people WHERE video_id = ?', 
                            (video['id'],)
                        ).fetchone()
                        st.wrf"–í—Å–µ–≥–æ –ª—é–¥–µ–π: {people_stats['total_people']}")
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–µ–∑–¥–∞–º
                        train_stats = conn.execute(
                            'SELECT COUNT(*) as total_trains FROM train_events WHERE video_id = ?', 
                            (video['id'],)
                        ).fetchone()
                        st.write(f"–°–æ–±—ã—Ç–∏–π –ø–æ–µ–∑–¥–æ–≤: {train_stats['total_trains']}")
                        
                        if st.button(f"–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤–∏–¥–µ–æ ID {video['id']}", key=f"load_{video['id']}"):
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ –≤–∏–¥–µ–æ
                            people_data_db = conn.execute(
                                'SELECT person_id, appearance_time, disappearance_time, waiting_minutes, reid_enabled FROM people WHERE video_id = ?',
                                (video['id'],)
                            ).fetchall()
                            
                            train_events_db = conn.execute(
                                'SELECT arrival_time, departure_time, duration_seconds FROM train_events WHERE video_id = ?',
                                (video['id'],)
                            ).fetchall()
                            
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                            if people_data_db:
                                st.subheader("–õ—é–¥–∏ –∏–∑ –ë–î")
                                df_people_db = pd.DataFrame(people_data_db)
                                st.dataframe(df_people_db)
                            
                            if train_events_db:
                                st.subheader("–ü–æ–µ–∑–¥–∞ –∏–∑ –ë–î")
                                df_train_db = pd.DataFrame(train_events_db)
                                st.dataframe(df_train_db)
            else:
                st.info("–í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π")
                fdlmgk;dfglk'dflgnlkdfglk