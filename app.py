import streamlit as st
import cv2
import easyocr
import pandas as pd
from ultralytics import YOLO
from supervision import LineZone, BoxAnnotator, LineZoneAnnotator, Detections
from supervision.geometry.core import Point
from datetime import datetime, timedelta
import tempfile
import numpy as np
from collections import OrderedDict
import os
import sqlite3
import json
from contextlib import contextmanager
import re

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
st.title("üöâ –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ —Å –∂–µ–ª–µ–∑–Ω–æ–¥–æ—Ä–æ–∂–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã")
st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
db_enabled = st.sidebar.checkbox("–°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö", value=True)
db_path = st.sidebar.text_input("–ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö", "platform_analysis.db")

# –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
confidence = st.sidebar.slider("Confidence", 0.0, 1.0, 0.4)
line_y = st.sidebar.slider("–ü–æ–∑–∏—Ü–∏—è –ª–∏–Ω–∏–∏", 0, 1080, 600)
skip_frames = st.sidebar.slider("–ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –∫–∞–¥—Ä–æ–≤", 1, 10, 2)
resize_factor = st.sidebar.slider("–£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è", 0.3, 1.0, 0.6)
disable_ocr = st.sidebar.checkbox("–û—Ç–∫–ª—é—á–∏—Ç—å OCR (—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏)", value=False)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–ª–∞—Å—Ç–∏ OCR
ocr_x = st.sidebar.slider("X-–ø–æ–∑–∏—Ü–∏—è OCR", 0, 1000, 10)
ocr_y = st.sidebar.slider("Y-–ø–æ–∑–∏—Ü–∏—è OCR", 0, 1000, 10)
ocr_width = st.sidebar.slider("–®–∏—Ä–∏–Ω–∞ OCR", 100, 800, 300)
ocr_height = st.sidebar.slider("–í—ã—Å–æ—Ç–∞ OCR", 20, 200, 50)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ü–≤–µ—Ç–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–µ–∑–¥–∞
st.sidebar.subheader("–¶–≤–µ—Ç–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ–µ–∑–¥–∞")
gray_lower = st.sidebar.slider("–°–µ—Ä—ã–π –Ω–∏–∂–Ω–∏–π –ø–æ—Ä–æ–≥", 0, 255, 50)
gray_upper = st.sidebar.slider("–°–µ—Ä—ã–π –≤–µ—Ä—Ö–Ω–∏–π –ø–æ—Ä–æ–≥", 0, 255, 200)
orange_lower_h = st.sidebar.slider("–û—Ä–∞–Ω–∂–µ–≤—ã–π H –Ω–∏–∂–Ω–∏–π", 0, 180, 5)
orange_upper_h = st.sidebar.slider("–û—Ä–∞–Ω–∂–µ–≤—ã–π H –≤–µ—Ä—Ö–Ω–∏–π", 0, 180, 15)
red_lower_h1 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H1 –Ω–∏–∂–Ω–∏–π", 0, 180, 0)
red_upper_h1 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H1 –≤–µ—Ä—Ö–Ω–∏–π", 0, 180, 10)
red_lower_h2 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H2 –Ω–∏–∂–Ω–∏–π", 0, 180, 170)
red_upper_h2 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H2 –≤–µ—Ä—Ö–Ω–∏–π", 0, 180, 180)

# ‚úÖ –£–õ–£–ß–®–ï–ù–ù–´–ô ReID —Å –∞–Ω–∞–ª–∏–∑–æ–º –¥–µ—Ç–∞–ª–µ–π –æ–¥–µ–∂–¥—ã
st.sidebar.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ ReID —Å –∞–Ω–∞–ª–∏–∑–æ–º –¥–µ—Ç–∞–ª–µ–π")
reid_threshold = st.sidebar.slider("–ü–æ—Ä–æ–≥ ReID —Å—Ö–æ–¥—Å—Ç–≤–∞", 0.1, 1.0, 0.7)
enable_reid = st.sidebar.checkbox("–í–∫–ª—é—á–∏—Ç—å ReID", value=True)
analyze_clothing = st.sidebar.checkbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–¥–µ–∂–¥—É –∏ –æ–±—É–≤—å", value=True)
clothing_detail_level = st.sidebar.slider("–£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–¥–µ–∂–¥—ã", 1, 3, 2)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Å—Ç–µ–π —Ç–µ–ª–∞
st.sidebar.subheader("–ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–µ–π —Ç–µ–ª–∞")
analyze_upper_body = st.sidebar.checkbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Ä—Ö–Ω—é—é —á–∞—Å—Ç—å", value=True)
analyze_lower_body = st.sidebar.checkbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏–∂–Ω—é—é —á–∞—Å—Ç—å", value=True)
analyze_shoes = st.sidebar.checkbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—É–≤—å", value=True)
analyze_head = st.sidebar.checkbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ–≤—É", value=False)

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
st.sidebar.subheader("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
train_number_ocr_enabled = st.sidebar.checkbox("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –Ω–æ–º–µ—Ä –ø–æ–µ–∑–¥–∞", value=True)

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è ---
def calculate_total_waiting_time(people_data):
    """–°—É–º–º–∏—Ä—É–µ—Ç –æ–±—â–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –≤—Å–µ—Ö –ª—é–¥–µ–π"""
    total_minutes = 0.0
    
    for person in people_data:
        waiting_str = person.get("–û–∂–∏–¥–∞–Ω–∏–µ", "0.0 –º–∏–Ω")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Å—Ç—Ä–æ–∫–∏ "X.X –º–∏–Ω"
        try:
            # –£–±–∏—Ä–∞–µ–º " –º–∏–Ω" –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ float
            if "–º–∏–Ω" in waiting_str:
                minutes = float(waiting_str.replace(" –º–∏–Ω", "").strip())
                total_minutes += minutes
        except (ValueError, AttributeError):
            continue
    
    return total_minutes

def analyze_waiting_distribution(people_data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è"""
    distribution = {
        "–º–µ–Ω–µ–µ_1_–º–∏–Ω": 0,
        "1_5_–º–∏–Ω": 0,
        "5_15_–º–∏–Ω": 0,
        "–±–æ–ª–µ–µ_15_–º–∏–Ω": 0
    }
    
    for person in people_data:
        waiting_str = person.get("–û–∂–∏–¥–∞–Ω–∏–µ", "0.0 –º–∏–Ω")
        
        try:
            if "–º–∏–Ω" in waiting_str:
                minutes = float(waiting_str.replace(" –º–∏–Ω", "").strip())
                
                if minutes < 1:
                    distribution["–º–µ–Ω–µ–µ_1_–º–∏–Ω"] += 1
                elif 1 <= minutes < 5:
                    distribution["1_5_–º–∏–Ω"] += 1
                elif 5 <= minutes < 15:
                    distribution["5_15_–º–∏–Ω"] += 1
                else:
                    distribution["–±–æ–ª–µ–µ_15_–º–∏–Ω"] += 1
                    
        except (ValueError, AttributeError):
            continue
    
    return distribution

# --- –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö ---
@contextmanager
def get_db_connection():
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î"""
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()

def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü"""
    with get_db_connection() as conn:
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ
        conn.execute('''
            CREATE TABLE IF NOT EXISTS videos (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT NOT NULL,
                processed_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                frame_count INTEGER,
                processed_frames INTEGER,
                duration_seconds REAL,
                resolution TEXT,
                fps REAL
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –æ –ª—é–¥—è—Ö
        conn.execute('''
            CREATE TABLE IF NOT EXISTS people (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                person_id INTEGER NOT NULL,
                appearance_time TEXT NOT NULL,
                disappearance_time TEXT,
                waiting_minutes REAL,
                reid_enabled BOOLEAN,
                clothing_features TEXT,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å–æ–±—ã—Ç–∏–π –ø–æ–µ–∑–¥–æ–≤
        conn.execute('''
            CREATE TABLE IF NOT EXISTS train_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                arrival_time TEXT NOT NULL,
                departure_time TEXT,
                duration_seconds REAL,
                train_number TEXT,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        conn.execute('''
            CREATE TABLE IF NOT EXISTS occupancy (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                timestamp TEXT NOT NULL,
                people_count INTEGER NOT NULL,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ü–≤–µ—Ç–æ–≤ –ø–æ–µ–∑–¥–∞
        conn.execute('''
            CREATE TABLE IF NOT EXISTS color_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                frame_index INTEGER NOT NULL,
                gray_percent REAL,
                orange_percent REAL,
                red_percent REAL,
                combined_percent REAL,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞
        conn.execute('''
            CREATE TABLE IF NOT EXISTS line_statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                in_count INTEGER DEFAULT 0,
                out_count INTEGER DEFAULT 0,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è
        conn.execute('''
            CREATE TABLE IF NOT EXISTS stay_statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                total_stay_minutes REAL,
                average_stay_minutes REAL,
                median_stay_minutes REAL,
                max_stay_minutes REAL,
                min_stay_minutes REAL,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è
        conn.execute('''
            CREATE TABLE IF NOT EXISTS waiting_statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                total_waiting_minutes REAL,
                average_waiting_minutes REAL,
                less_1_min INTEGER,
                between_1_5_min INTEGER,
                between_5_15_min INTEGER,
                more_15_min INTEGER,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ª—é–¥–µ–π –≤–æ–∑–ª–µ –ø–æ–µ–∑–¥–∞
        conn.execute('''
            CREATE TABLE IF NOT EXISTS train_proximity (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                timestamp TEXT NOT NULL,
                people_near_train INTEGER NOT NULL,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        conn.execute('''
            CREATE TABLE IF NOT EXISTS processing_settings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id INTEGER,
                settings_json TEXT NOT NULL,
                FOREIGN KEY (video_id) REFERENCES videos (id)
            )
        ''')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–∞ clothing_features –≤ —Ç–∞–±–ª–∏—Ü–µ people
            cursor = conn.execute("PRAGMA table_info(people)")
            columns = [column[1] for column in cursor.fetchall()]
            
            if 'clothing_features' not in columns:
                conn.execute('ALTER TABLE people ADD COLUMN clothing_features TEXT')
                st.sidebar.info("–î–æ–±–∞–≤–ª–µ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π —Å—Ç–æ–ª–±–µ—Ü clothing_features –≤ —Ç–∞–±–ª–∏—Ü—É people")
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–∞ train_number –≤ —Ç–∞–±–ª–∏—Ü–µ train_events
            cursor = conn.execute("PRAGMA table_info(train_events)")
            columns = [column[1] for column in cursor.fetchall()]
            
            if 'train_number' not in columns:
                conn.execute('ALTER TABLE train_events ADD COLUMN train_number TEXT')
                st.sidebar.info("–î–æ–±–∞–≤–ª–µ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π —Å—Ç–æ–ª–±–µ—Ü train_number –≤ —Ç–∞–±–ª–∏—Ü—É train_events")
                
        except Exception as e:
            st.sidebar.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î: {e}")
        
        conn.commit()

def save_video_info(conn, video_info):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ"""
    cursor = conn.execute('''
        INSERT INTO videos (filename, frame_count, processed_frames, duration_seconds, resolution, fps)
        VALUES (?, ?, ?, ?, ?, ?)
    ''', (
        video_info['filename'],
        video_info['frame_count'],
        video_info['processed_frames'],
        video_info['duration_seconds'],
        video_info['resolution'],
        video_info['fps']
    ))
    return cursor.lastrowid

def save_people_data(conn, video_id, people_data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ª—é–¥—è—Ö"""
    for person in people_data:
        waiting_minutes = None
        if person["–û–∂–∏–¥–∞–Ω–∏–µ"] != "0.0 –º–∏–Ω":
            try:
                waiting_minutes = float(person["–û–∂–∏–¥–∞–Ω–∏–µ"].replace(" –º–∏–Ω", ""))
            except:
                waiting_minutes = 0.0
        else:
            waiting_minutes = 0.0
        
        clothing_features = person.get("ClothingFeatures", "{}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–∞ clothing_features –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π
        cursor = conn.execute("PRAGMA table_info(people)")
        columns = [column[1] for column in cursor.fetchall()]
        
        if 'clothing_features' in columns:
            conn.execute('''
                INSERT INTO people (video_id, person_id, appearance_time, disappearance_time, waiting_minutes, reid_enabled, clothing_features)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                video_id,
                person["ID"],
                person["–ü–æ—è–≤–ª–µ–Ω–∏–µ"],
                person["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] if person["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] != "-" else None,
                waiting_minutes,
                person["ReID"] == "‚úì",
                clothing_features
            ))
        else:
            # –ï—Å–ª–∏ —Å—Ç–æ–ª–±—Ü–∞ –Ω–µ—Ç, –≤—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –Ω–µ–≥–æ
            conn.execute('''
                INSERT INTO people (video_id, person_id, appearance_time, disappearance_time, waiting_minutes, reid_enabled)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                video_id,
                person["ID"],
                person["–ü–æ—è–≤–ª–µ–Ω–∏–µ"],
                person["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] if person["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] != "-" else None,
                waiting_minutes,
                person["ReID"] == "‚úì"
            ))

def save_train_events(conn, video_id, train_events):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–±—ã—Ç–∏—è –ø–æ–µ–∑–¥–æ–≤"""
    for event in train_events:
        duration = None
        if event["–ü—Ä–∏–±—ã—Ç–∏–µ"] and event["–£–±—ã—Ç–∏–µ"]:
            try:
                t1 = datetime.strptime(event["–ü—Ä–∏–±—ã—Ç–∏–µ"], "%H:%M:%S")
                t2 = datetime.strptime(event["–£–±—ã—Ç–∏–µ"], "%H:%M:%S")
                duration = (t2 - t1).total_seconds()
            except:
                duration = None
        
        conn.execute('''
            INSERT INTO train_events (video_id, arrival_time, departure_time, duration_seconds, train_number)
            VALUES (?, ?, ?, ?, ?)
        ''', (video_id, event["–ü—Ä–∏–±—ã—Ç–∏–µ"], event["–£–±—ã—Ç–∏–µ"], duration, event.get("–ù–æ–º–µ—Ä", None)))

def save_occupancy(conn, video_id, occupancy):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏"""
    for occ in occupancy:
        conn.execute('''
            INSERT INTO occupancy (video_id, timestamp, people_count)
            VALUES (?, ?, ?)
        ''', (video_id, occ["time"], occ["people"]))

def save_color_analysis(conn, video_id, color_analysis):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤"""
    for color_data in color_analysis:
        conn.execute('''
            INSERT INTO color_analysis (video_id, frame_index, gray_percent, orange_percent, red_percent, combined_percent)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            video_id,
            color_data["frame"],
            color_data["gray"],
            color_data["orange"],
            color_data["red"],
            color_data["combined"]
        ))

def save_line_statistics(conn, video_id, in_count, out_count):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ª–∏–Ω–∏–∏"""
    conn.execute('''
        INSERT INTO line_statistics (video_id, in_count, out_count)
        VALUES (?, ?, ?)
    ''', (video_id, in_count, out_count))

def save_stay_statistics(conn, video_id, stay_stats):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è"""
    conn.execute('''
        INSERT INTO stay_statistics (video_id, total_stay_minutes, average_stay_minutes, median_stay_minutes, max_stay_minutes, min_stay_minutes)
        VALUES (?, ?, ?, ?, ?, ?)
    ''', (
        video_id,
        stay_stats['total_stay_minutes'],
        stay_stats['average_stay_minutes'],
        stay_stats['median_stay_minutes'],
        stay_stats['max_stay_minutes'],
        stay_stats['min_stay_minutes']
    ))

def save_waiting_statistics(conn, video_id, waiting_stats):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è"""
    conn.execute('''
        INSERT INTO waiting_statistics (video_id, total_waiting_minutes, average_waiting_minutes, less_1_min, between_1_5_min, between_5_15_min, more_15_min)
        VALUES (?, ?, ?, ?, ?, ?, ?)
    ''', (
        video_id,
        waiting_stats['total_waiting_minutes'],
        waiting_stats['average_waiting_minutes'],
        waiting_stats['less_1_min'],
        waiting_stats['between_1_5_min'],
        waiting_stats['between_5_15_min'],
        waiting_stats['more_15_min']
    ))

def save_train_proximity(conn, video_id, proximity_data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ª—é–¥—è—Ö –≤–æ–∑–ª–µ –ø–æ–µ–∑–¥–∞"""
    for data in proximity_data:
        conn.execute('''
            INSERT INTO train_proximity (video_id, timestamp, people_near_train)
            VALUES (?, ?, ?)
        ''', (video_id, data["time"], data["people_near_train"]))

def save_processing_settings(conn, video_id, settings):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    conn.execute('''
        INSERT INTO processing_settings (video_id, settings_json)
        VALUES (?, ?)
    ''', (video_id, json.dumps(settings)))

def load_previous_analyses():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∞–Ω–∞–ª–∏–∑–æ–≤"""
    if not os.path.exists(db_path):
        return []
    
    try:
        with get_db_connection() as conn:
            cursor = conn.execute('''
                SELECT id, filename, processed_date, frame_count, processed_frames 
                FROM videos 
                ORDER BY processed_date DESC
            ''')
            return cursor.fetchall()
    except:
        return []

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
if db_enabled:
    init_database()

# –ú–æ–¥–µ–ª—å
model = YOLO("yolov8n.pt")

# OCR —Ä–∏–¥–µ—Ä
reader = None
if not disable_ocr:
    try:
        reader = easyocr.Reader(['en', 'ru'], gpu=False)
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å OCR: {e}")
        reader = None

# –ê–Ω–Ω–æ—Ç–∞—Ç–æ—Ä—ã
box_annotator = BoxAnnotator()
line_annotator = LineZoneAnnotator()
line = LineZone(start=Point(0, line_y), end=Point(9999, line_y))

# –•—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–∞–Ω–Ω—ã—Ö
people_data = []
train_events = []
occupancy = []
train_proximity_data = []

# ‚úÖ –£–õ–£–ß–®–ï–ù–ù–´–ô ReID —Å –∞–Ω–∞–ª–∏–∑–æ–º –¥–µ—Ç–∞–ª–µ–π –æ–¥–µ–∂–¥—ã
class AdvancedReIDStorage:
    def __init__(self, similarity_threshold=0.7):
        self.similarity_threshold = similarity_threshold
        self.known_features = OrderedDict()  # ID -> —Å–ª–æ–≤–∞—Ä—å —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        self.orb = cv2.ORB_create()
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        
    def extract_detailed_features(self, image, bbox):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –æ–¥–µ–∂–¥—ã –∏ –æ–±—É–≤–∏"""
        try:
            # –í—ã—Ä–µ–∑–∞–µ–º –æ–±–ª–∞—Å—Ç—å —á–µ–ª–æ–≤–µ–∫–∞
            x1, y1, x2, y2 = [int(coord) for coord in bbox]
            person_crop = image[y1:y2, x1:x2]
            
            if person_crop.size == 0:
                return None
            
            height, width = person_crop.shape[:2]
            
            # ‚úÖ –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ù–ê –ß–ê–°–¢–ò –¢–ï–õ–ê –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –î–ï–¢–ê–õ–ï–ô
            parts_features = {}
            
            # 1. –í–µ—Ä—Ö–Ω—è—è —á–∞—Å—Ç—å —Ç–µ–ª–∞ (–≥–æ–ª–æ–≤–∞ –∏ —Ç–æ—Ä—Å)
            if analyze_upper_body and height > 40:
                upper_height = int(height * 0.6)  # –í–µ—Ä—Ö–Ω–∏–µ 60%
                upper_part = person_crop[0:upper_height, :]
                parts_features['upper_body'] = self.analyze_clothing_region(upper_part, "upper")
            
            # 2. –ù–∏–∂–Ω—è—è —á–∞—Å—Ç—å —Ç–µ–ª–∞ (–±—Ä—é–∫–∏/—é–±–∫–∞)
            if analyze_lower_body and height > 40:
                lower_start = int(height * 0.4)  # –ù–∏–∂–Ω–∏–µ 60%
                lower_part = person_crop[lower_start:, :]
                parts_features['lower_body'] = self.analyze_clothing_region(lower_part, "lower")
            
            # 3. –û–±—É–≤—å (—Å–∞–º—ã–µ –Ω–∏–∂–Ω–∏–µ 20%)
            if analyze_shoes and height > 50:
                shoes_start = int(height * 0.8)  # –ù–∏–∂–Ω–∏–µ 20%
                shoes_part = person_crop[shoes_start:, :]
                parts_features['shoes'] = self.analyze_shoes_region(shoes_part)
            
            # 4. –ì–æ–ª–æ–≤–∞ (–≤–µ—Ä—Ö–Ω–∏–µ 25%)
            if analyze_head and height > 40:
                head_height = int(height * 0.25)
                head_part = person_crop[0:head_height, :]
                parts_features['head'] = self.analyze_head_region(head_part)
            
            # 5. –û–±—â–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≤—Å–µ–≥–æ —Ç–µ–ª–∞
            parts_features['whole_body'] = self.analyze_whole_body(person_crop)
            
            return parts_features
        except Exception as e:
            return None
    
    def analyze_clothing_region(self, region, region_type):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–≥–∏–æ–Ω –æ–¥–µ–∂–¥—ã"""
        features = {}
        
        # –¶–≤–µ—Ç–æ–≤—ã–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –≤ —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞—Ö
        features['color_hsv'] = self.compute_color_histogram(region, 'HSV')
        features['color_lab'] = self.compute_color_histogram(region, 'LAB')
        features['color_rgb'] = self.compute_color_histogram(region, 'RGB')
        
        # –¢–µ–∫—Å—Ç—É—Ä–∞ —Å –ø–æ–º–æ—â—å—é LBP (Local Binary Patterns)
        features['texture'] = self.compute_texture_features(region)
        
        # ORB –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ–¥–µ–∂–¥—ã
        features['orb_descriptors'] = self.compute_orb_features(region)
        
        # –î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —Ü–≤–µ—Ç–∞
        features['dominant_colors'] = self.extract_dominant_colors(region)
        
        return features
    
    def analyze_shoes_region(self, region):
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–±—É–≤–∏"""
        features = {}
        
        # –û–±—É–≤—å —á–∞—Å—Ç–æ –∏–º–µ–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Ü–≤–µ—Ç–∞
        features['color_hsv'] = self.compute_color_histogram(region, 'HSV')
        features['color_lab'] = self.compute_color_histogram(region, 'LAB')
        
        # –¢–µ–∫—Å—Ç—É—Ä–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ–±—É–≤–∏ (–∫–æ–∂–∞, —Ç–∫–∞–Ω—å –∏ —Ç.–¥.)
        features['texture'] = self.compute_texture_features(region)
        
        # –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º—ã (–µ—Å–ª–∏ –æ–±—É–≤—å –≤–∏–¥–Ω–∞ —á–µ—Ç–∫–æ)
        features['shape_features'] = self.compute_shape_features(region)
        
        return features
    
    def analyze_head_region(self, region):
        """–ê–Ω–∞–ª–∏–∑ –≥–æ–ª–æ–≤—ã (–≤–æ–ª–æ—Å—ã, –≥–æ–ª–æ–≤–Ω—ã–µ —É–±–æ—Ä—ã)"""
        features = {}
        
        features['color_hsv'] = self.compute_color_histogram(region, 'HSV')
        features['color_lab'] = self.compute_color_histogram(region, 'LAB')
        features['texture'] = self.compute_texture_features(region)
        
        return features
    
    def analyze_whole_body(self, region):
        """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ–≥–æ —Ç–µ–ª–∞"""
        features = {}
        
        features['color_hsv'] = self.compute_color_histogram(region, 'HSV')
        features['color_lab'] = self.compute_color_histogram(region, 'LAB')
        features['orb_descriptors'] = self.compute_orb_features(region)
        features['texture'] = self.compute_texture_features(region)
        
        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω (–º–æ–∂–µ—Ç –ø–æ–º–æ—á—å –≤ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–ª–æ—Å–ª–æ–∂–µ–Ω–∏—è)
        features['aspect_ratio'] = region.shape[1] / region.shape[0] if region.shape[0] > 0 else 0
        
        return features
    
    def compute_color_histogram(self, image, color_space='HSV'):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ü–≤–µ—Ç–æ–≤—É—é –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ"""
        try:
            if color_space == 'HSV':
                converted = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
                channels = [0, 1, 2]
                hist_size = [8, 8, 8]
                ranges = [0, 180, 0, 256, 0, 256]
            elif color_space == 'LAB':
                converted = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
                channels = [0, 1, 2]
                hist_size = [8, 8, 8]
                ranges = [0, 256, 0, 256, 0, 256]
            else:  # RGB
                converted = image
                channels = [0, 1, 2]
                hist_size = [8, 8, 8]
                ranges = [0, 256, 0, 256, 0, 256]
            
            hist = cv2.calcHist([converted], channels, None, hist_size, ranges)
            hist = cv2.normalize(hist, hist).flatten()
            return hist
        except:
            return np.array([])
    
    def compute_texture_features(self, image):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç—É—Ä—ã —Å –ø–æ–º–æ—â—å—é LBP"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # LBP (Local Binary Patterns)
            radius = 3
            n_points = 8 * radius
            lbp = self.local_binary_pattern(gray, n_points, radius, method='uniform')
            
            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ LBP
            hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))
            hist = hist.astype("float")
            hist /= (hist.sum() + 1e-7)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            
            return hist
        except:
            return np.array([])
    
    def local_binary_pattern(self, image, num_points, radius, method='uniform'):
        """–†–µ–∞–ª–∏–∑–∞—Ü–∏—è Local Binary Pattern"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è LBP
        gray = image
        if len(image.shape) > 2:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        lbp = np.zeros_like(gray)
        for i in range(radius, gray.shape[0]-radius):
            for j in range(radius, gray.shape[1]-radius):
                center = gray[i,j]
                binary_code = 0
                for k in range(num_points):
                    angle = 2 * np.pi * k / num_points
                    x = i + int(radius * np.sin(angle))
                    y = j + int(radius * np.cos(angle))
                    if gray[x,y] >= center:
                        binary_code |= (1 << k)
                lbp[i,j] = binary_code
        
        return lbp
    
    def compute_orb_features(self, image):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ORB –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            keypoints, descriptors = self.orb.detectAndCompute(gray, None)
            return descriptors
        except:
            return None
    
    def compute_shape_features(self, region):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º—ã (–¥–ª—è –æ–±—É–≤–∏)"""
        try:
            gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            
            # –ú–æ–º–µ–Ω—Ç—ã —Ñ–æ—Ä–º—ã
            moments = cv2.moments(edges)
            
            features = []
            if moments['m00'] != 0:
                # –¶–µ–Ω—Ç—Ä –º–∞—Å—Å
                cx = moments['m10'] / moments['m00']
                cy = moments['m01'] / moments['m00']
                features.extend([cx, cy])
            
            # Hu moments (–∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç—ã –∫ –º–∞—Å—à—Ç–∞–±—É –∏ –≤—Ä–∞—â–µ–Ω–∏—é)
            hu_moments = cv2.HuMoments(moments)
            if hu_moments is not None:
                features.extend(hu_moments.flatten())
            
            return np.array(features)
        except:
            return np.array([])
    
    def extract_dominant_colors(self, image, k=3):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —Ü–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é k-means"""
        try:
            pixels = image.reshape(-1, 3)
            pixels = np.float32(pixels)
            
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)
            _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ uint8
            centers = np.uint8(centers)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω–æ—Å—Ç–∏
            unique, counts = np.unique(labels, return_counts=True)
            sorted_indices = np.argsort(-counts)
            dominant_colors = centers[sorted_indices]
            
            return dominant_colors.flatten()
        except:
            return np.array([])
    
    def calculate_features_similarity(self, features1, features2):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–±–æ—Ä–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if features1 is None or features2 is None:
            return 0.0
        
        total_similarity = 0.0
        weight_sum = 0.0
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å —Ç–µ–ª–∞
        for part in ['upper_body', 'lower_body', 'shoes', 'head', 'whole_body']:
            if part in features1 and part in features2:
                part_similarity = self.compare_part_features(features1[part], features2[part])
                
                # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π —Ç–µ–ª–∞
                weights = {
                    'upper_body': 0.3,
                    'lower_body': 0.25,
                    'shoes': 0.2,
                    'head': 0.15,
                    'whole_body': 0.1
                }
                
                total_similarity += part_similarity * weights.get(part, 0.1)
                weight_sum += weights.get(part, 0.1)
        
        if weight_sum > 0:
            return total_similarity / weight_sum
        else:
            return 0.0
    
    def compare_part_features(self, part1, part2):
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —á–∞—Å—Ç–∏ —Ç–µ–ª–∞"""
        similarity = 0.0
        feature_count = 0
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ü–≤–µ—Ç–æ–≤—ã–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        for color_space in ['color_hsv', 'color_lab', 'color_rgb']:
            if color_space in part1 and color_space in part2:
                if len(part1[color_space]) > 0 and len(part2[color_space]) > 0:
                    try:
                        color_sim = cv2.compareHist(part1[color_space].astype(np.float32), 
                                                   part2[color_space].astype(np.float32), 
                                                   cv2.HISTCMP_CORREL)
                        if not np.isnan(color_sim):
                            similarity += max(0, color_sim) * 0.3
                            feature_count += 0.3
                    except:
                        pass
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—É—Ä—É
        if 'texture' in part1 and 'texture' in part2:
            if len(part1['texture']) > 0 and len(part2['texture']) > 0:
                try:
                    texture_sim = 1 - np.linalg.norm(part1['texture'] - part2['texture'])
                    similarity += max(0, texture_sim) * 0.3
                    feature_count += 0.3
                except:
                    pass
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º ORB –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã
        if 'orb_descriptors' in part1 and 'orb_descriptors' in part2:
            desc1 = part1['orb_descriptors']
            desc2 = part2['orb_descriptors']
            if desc1 is not None and desc2 is not None and len(desc1) > 0 and len(desc2) > 0:
                try:
                    matches = self.bf.match(desc1, desc2)
                    if len(matches) > 0:
                        orb_sim = len(matches) / min(len(desc1), len(desc2))
                        similarity += min(orb_sim, 1.0) * 0.2
                        feature_count += 0.2
                except:
                    pass
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —Ü–≤–µ—Ç–∞
        if 'dominant_colors' in part1 and 'dominant_colors' in part2:
            if len(part1['dominant_colors']) > 0 and len(part2['dominant_colors']) > 0:
                try:
                    color_dist = np.linalg.norm(part1['dominant_colors'] - part2['dominant_colors'])
                    color_sim = 1 - min(color_dist / 100, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                    similarity += max(0, color_sim) * 0.2
                    feature_count += 0.2
                except:
                    pass
        
        if feature_count > 0:
            return similarity / feature_count
        else:
            return 0.0
    
    def find_best_match(self, new_features):
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        if not self.known_features:
            return None, 0.0
            
        best_match_id = None
        best_similarity = 0.0
        
        for person_id, stored_features in self.known_features.items():
            similarity = self.calculate_features_similarity(new_features, stored_features)
            
            if similarity > best_similarity and similarity > self.similarity_threshold:
                best_similarity = similarity
                best_match_id = person_id
                
        return best_match_id, best_similarity
    
    def add_person(self, person_id, features):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        self.known_features[person_id] = features
    
    def update_person(self, person_id, new_features):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞"""
        if person_id in self.known_features:
            # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            old_features = self.known_features[person_id]
            alpha = 0.7  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞–±—ã–≤–∞–Ω–∏—è
            
            updated_features = {}
            for part in ['upper_body', 'lower_body', 'shoes', 'head', 'whole_body']:
                if part in old_features and part in new_features:
                    updated_features[part] = {}
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                    for feature_type in old_features[part]:
                        if feature_type in new_features[part]:
                            old_val = old_features[part][feature_type]
                            new_val = new_features[part][feature_type]
                            
                            if isinstance(old_val, np.ndarray) and isinstance(new_val, np.ndarray):
                                if len(old_val) == len(new_val):
                                    updated_features[part][feature_type] = (
                                        alpha * old_val + (1 - alpha) * new_val
                                    )
                            else:
                                # –î–ª—è –Ω–µ—á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–µ
                                updated_features[part][feature_type] = new_val
                elif part in new_features:
                    updated_features[part] = new_features[part]
            
            self.known_features[person_id] = updated_features
        else:
            self.add_person(person_id, new_features)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ ReID
reid_storage = AdvancedReIDStorage(similarity_threshold=reid_threshold) if enable_reid else None

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ü–≤–µ—Ç–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–µ–∑–¥–∞
def detect_train_colors(roi):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ü–≤–µ—Ç–æ–≤ –ø–æ–µ–∑–¥–∞ –≤ –æ–±–ª–∞—Å—Ç–∏"""
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    
    gray_mask = cv2.inRange(roi, (gray_lower, gray_lower, gray_lower), (gray_upper, gray_upper, gray_upper))
    
    lower_orange = np.array([orange_lower_h, 100, 100])
    upper_orange = np.array([orange_upper_h, 255, 255])
    orange_mask = cv2.inRange(hsv, lower_orange, upper_orange)
    
    lower_red1 = np.array([red_lower_h1, 100, 100])
    upper_red1 = np.array([red_upper_h1, 255, 255])
    lower_red2 = np.array([red_lower_h2, 100, 100])
    upper_red2 = np.array([red_upper_h2, 255, 255])
    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    red_mask = cv2.bitwise_or(red_mask1, red_mask2)
    
    combined_mask = cv2.bitwise_or(gray_mask, orange_mask)
    combined_mask = cv2.bitwise_or(combined_mask, red_mask)
    
    total_pixels = roi.shape[0] * roi.shape[1]
    if total_pixels == 0:
        return 0, 0, 0, 0
    
    gray_percent = np.sum(gray_mask > 0) / total_pixels * 100
    orange_percent = np.sum(orange_mask > 0) / total_pixels * 100
    red_percent = np.sum(red_mask > 0) / total_pixels * 100
    combined_percent = np.sum(combined_mask > 0) / total_pixels * 100
    
    return gray_percent, orange_percent, red_percent, combined_percent

def is_in_train_zone(x1, y1, x2, y2, frame_width, frame_height):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –æ–±—ä–µ–∫—Ç –≤ –∑–æ–Ω–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–µ–∑–¥–∞"""
    zone_x1 = train_zone_x
    zone_x2 = train_zone_x + train_zone_width
    zone_y1 = train_zone_y
    zone_y2 = train_zone_y + train_zone_height

    center_x = (x1 + x2) / 2
    center_y = (y1 + y2) / 2
    in_zone = (zone_x1 <= center_x <= zone_x2) and (zone_y1 <= center_y <= zone_y2)
    return in_zone, (zone_x1, zone_y1, zone_x2, zone_y2)

# ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è
def calculate_stay_statistics(people_data, occupancy):
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è –≤—Å–µ—Ö –ª—é–¥–µ–π"""
    if not people_data:
        return {
            'total_stay_minutes': 0,
            'average_stay_minutes': 0,
            'median_stay_minutes': 0,
            'max_stay_minutes': 0,
            'min_stay_minutes': 0,
            'total_people': 0
        }
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∏–∑ occupancy –¥–ª—è —Ç–µ—Ö, –∫—Ç–æ –Ω–µ —É—à–µ–ª
    last_time_str = occupancy[-1]["time"] if occupancy else "00:00:00"
    
    stay_times = []
    
    for person in people_data:
        if person["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] != "-":
            # –£ —á–µ–ª–æ–≤–µ–∫–∞ –µ—Å—Ç—å –≤—Ä–µ–º—è —É—Ö–æ–¥–∞
            try:
                start_time = datetime.strptime(person["–ü–æ—è–≤–ª–µ–Ω–∏–µ"], "%H:%M:%S")
                end_time = datetime.strptime(person["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"], "%H:%M:%S")
                
                # –ï—Å–ª–∏ –≤—Ä–µ–º—è —É—Ö–æ–¥–∞ –º–µ–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–∏—Ö–æ–¥–∞, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —ç—Ç–æ —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å
                if end_time < start_time:
                    end_time = end_time.replace(day=end_time.day + 1)
                
                stay_seconds = (end_time - start_time).total_seconds()
                stay_minutes = stay_seconds / 60
                stay_times.append(stay_minutes)
                
            except Exception as e:
                continue
    
    if not stay_times:
        return {
            'total_stay_minutes': 0,
            'average_stay_minutes': 0,
            'median_stay_minutes': 0,
            'max_stay_minutes': 0,
            'min_stay_minutes': 0,
            'total_people': len(people_data)
        }
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    total_stay_minutes = sum(stay_times)
    average_stay_minutes = total_stay_minutes / len(stay_times)
    median_stay_minutes = np.median(stay_times)
    max_stay_minutes = max(stay_times)
    min_stay_minutes = min(stay_times)
    
    return {
        'total_stay_minutes': total_stay_minutes,
        'average_stay_minutes': average_stay_minutes,
        'median_stay_minutes': median_stay_minutes,
        'max_stay_minutes': max_stay_minutes,
        'min_stay_minutes': min_stay_minutes,
        'total_people': len(people_data),
        'people_with_complete_data': len(stay_times)
    }

# --- –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö ---
st.sidebar.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏")

if db_enabled:
    # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∞–Ω–∞–ª–∏–∑—ã
    previous_analyses = load_previous_analyses()
    if previous_analyses:
        st.sidebar.subheader("–ü—Ä–µ–¥—ã–¥—É—â–∏–µ –∞–Ω–∞–ª–∏–∑—ã")
        for analysis in previous_analyses:
            st.sidebar.write(f"{analysis['filename']} - {analysis['processed_date']}")

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏ –≤–∏–¥–µ–æ —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã", type=["mp4", "avi", "mov"])

if uploaded_file:
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    processing_settings = {
        "confidence": confidence,
        "line_y": line_y,
        "skip_frames": skip_frames,
        "resize_factor": resize_factor,
        "disable_ocr": disable_ocr,
        "ocr_x": ocr_x,
        "ocr_y": ocr_y,
        "ocr_width": ocr_width,
        "ocr_height": ocr_height,
        "reid_threshold": reid_threshold,
        "enable_reid": enable_reid,
        "analyze_clothing": analyze_clothing,
        "clothing_detail_level": clothing_detail_level,
        "analyze_upper_body": analyze_upper_body,
        "analyze_lower_body": analyze_lower_body,
        "analyze_shoes": analyze_shoes,
        "analyze_head": analyze_head,
        "train_number_ocr_enabled": train_number_ocr_enabled
    }
    
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    video_path = tfile.name

    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    original_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps if fps > 0 else 0
    
    # === –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ó–û–ù–ê –ü–û–ï–ó–î–ê (–ü–†–ê–í–ê–Ø –ß–ê–°–¢–¨ –ö–ê–î–†–ê) ===
    # –ü–æ–µ–∑–¥ –≤—Å–µ–≥–¥–∞ —Å–ø—Ä–∞–≤–∞ –∏ –≤ –Ω–∏–∂–Ω–∏—Ö ~70% –∫–∞–¥—Ä–∞
    train_zone_x = int(original_w * 0.55)          # –Ω–∞—á–∏–Ω–∞—è —Å 55% —à–∏—Ä–∏–Ω—ã
    train_zone_width = original_w - train_zone_x    # –¥–æ –∫–æ–Ω—Ü–∞ –∫–∞–¥—Ä–∞
    train_zone_y = int(original_h * 0.25)           # –æ—Ç 25% –≤—ã—Å–æ—Ç—ã (—á—Ç–æ–±—ã –Ω–µ —Ü–µ–ø–ª—è—Ç—å –Ω–µ–±–æ/–∫—Ä—ã—à—É)
    train_zone_height = original_h - train_zone_y
    
    st.sidebar.info(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–æ–Ω–∞ –ø–æ–µ–∑–¥–∞: {train_zone_x}x{train_zone_y} - {train_zone_width}x{train_zone_height}")
    
    process_w = int(original_w * resize_factor)
    process_h = int(original_h * resize_factor)

    stframe = st.empty()
    progress = st.progress(0)

    # –î–ª—è –ø–æ–µ–∑–¥–∞
    train_present = False
    train_arrival_time = None
    train_number = None
    tracked_ids = set()
    
    # –î–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ª—é–¥–µ–π –≤–æ–∑–ª–µ –ø–æ–µ–∑–¥–∞
    max_people_near_train = 0
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ —Å—Ç–∞—Ä—ã—Ö ID –∫ –Ω–æ–≤—ã–º —á–µ—Ä–µ–∑ ReID
    id_mapping = {}  # –Ω–æ–≤—ã–π_tracker_id -> —Å—Ç–∞—Ä—ã–π_person_id
    next_person_id = 1
    
    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ü–≤–µ—Ç–æ–≤
    color_analysis_data = []

    frame_idx = 0
    processed_frames = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –∫–∞–¥—Ä—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        if frame_idx % skip_frames != 0:
            frame_idx += 1
            continue

        # –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if resize_factor < 1.0:
            process_frame = cv2.resize(frame, (process_w, process_h))
        else:
            process_frame = frame

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
        timestamp_str = "00:00:00"
        current_dt = datetime.now()
        
        if not disable_ocr and reader is not None:
            try:
                y1 = max(0, min(ocr_y, frame.shape[0] - ocr_height))
                y2 = min(frame.shape[0], y1 + ocr_height)
                x1 = max(0, min(ocr_x, frame.shape[1] - ocr_width))
                x2 = min(frame.shape[1], x1 + ocr_width)
                
                crop = frame[y1:y2, x1:x2]
                gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
                enhanced = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)
                blurred = cv2.GaussianBlur(enhanced, (3, 3), 0)
                
                result = reader.readtext(blurred, detail=0, paragraph=True)
                
                if result:
                    timestamp_str = result[0]
                    time_formats = ["%H:%M:%S", "%H:%M", "%I:%M:%S %p", "%I:%M %p"]
                    
                    for fmt in time_formats:
                        try:
                            current_time = datetime.strptime(timestamp_str, fmt).time()
                            current_dt = datetime.combine(datetime.today(), current_time)
                            break
                        except:
                            continue
                            
            except Exception as e:
                st.sidebar.warning(f"–û—à–∏–±–∫–∞ OCR: {e}")

        # –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
        results = model.track(process_frame, persist=True, conf=confidence, 
                            classes=[0, 2, 3, 5, 6, 7], tracker="bytetrack.yaml", verbose=False)[0]
        
        # –°–æ–∑–¥–∞–µ–º Detections –æ–±—ä–µ–∫—Ç
        if results.boxes.id is not None:
            boxes = results.boxes.xyxy.cpu().numpy()
            confidence_scores = results.boxes.conf.cpu().numpy()
            class_ids = results.boxes.cls.cpu().numpy().astype(int)
            tracker_ids = results.boxes.id.cpu().numpy().astype(int)
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
            if resize_factor < 1.0:
                boxes = boxes / resize_factor
            
            detections = Detections(
                xyxy=boxes,
                confidence=confidence_scores,
                class_id=class_ids,
                tracker_id=tracker_ids
            )
            
            tracks = tracker_ids
        else:
            detections = Detections(
                xyxy=np.empty((0, 4)),
                confidence=np.array([]),
                class_id=np.array([], dtype=int)
            )
            tracks = None

        # ‚úÖ –£–õ–£–ß–®–ï–ù–ù–´–ô ReID —Å –∞–Ω–∞–ª–∏–∑–æ–º –¥–µ—Ç–∞–ª–µ–π –æ–¥–µ–∂–¥—ã
        current_people_tracks = []
        reid_matches = {}
        
        if enable_reid and reid_storage is not None and tracks is not None and analyze_clothing:
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª—é–¥–µ–π
            people_indices = np.where(detections.class_id == 0)[0]
            
            for idx in people_indices:
                tracker_id = int(tracks[idx])
                bbox = detections.xyxy[idx]
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –æ–¥–µ–∂–¥—ã
                features = reid_storage.extract_detailed_features(frame, bbox)
                
                if features is not None:
                    # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ª—é–¥—è—Ö
                    matched_id, similarity = reid_storage.find_best_match(features)
                    
                    if matched_id is not None and similarity > reid_threshold:
                        # –ù–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π ID
                        reid_matches[tracker_id] = matched_id
                        reid_storage.update_person(matched_id, features)
                        current_people_tracks.append(matched_id)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–¥–µ–∂–¥–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        clothing_info = f"Match: {similarity:.2f}"
                    else:
                        # –ù–æ–≤—ã–π —á–µ–ª–æ–≤–µ–∫ –∏–ª–∏ –Ω–µ—Ç —Ö–æ—Ä–æ—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                        if tracker_id not in id_mapping:
                            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π ID
                            new_person_id = next_person_id
                            next_person_id += 1
                            id_mapping[tracker_id] = new_person_id
                            reid_storage.add_person(new_person_id, features)
                            current_people_tracks.append(new_person_id)
                        else:
                            # –£–∂–µ –µ—Å—Ç—å –º–∞–ø–ø–∏–Ω–≥
                            current_people_tracks.append(id_mapping[tracker_id])
                else:
                    # –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º tracker_id
                    if tracker_id not in id_mapping:
                        new_person_id = next_person_id
                        next_person_id += 1
                        id_mapping[tracker_id] = new_person_id
                    current_people_tracks.append(id_mapping[tracker_id])
        
        # –¢–µ–∫—É—â–µ–µ –∫–æ–ª-–≤–æ –ª—é–¥–µ–π
        people_count = np.sum(detections.class_id == 0) if len(detections) > 0 else 0
        occupancy.append({"time": current_dt.strftime("%H:%M:%S"), "people": people_count})

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ª—é–¥–µ–π —Å —É—á–µ—Ç–æ–º ReID
        if tracks is not None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º ReID ID –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã, –∏–Ω–∞—á–µ tracker_id
            if enable_reid and analyze_clothing and current_people_tracks:
                current_ids = set(current_people_tracks)
            else:
                current_ids = set(tracks[detections.class_id == 0])
            
            appeared = current_ids - tracked_ids
            disappeared = tracked_ids - current_ids

            for person_id in appeared:
                people_data.append({
                    "ID": int(person_id), 
                    "–ü–æ—è–≤–ª–µ–Ω–∏–µ": current_dt.strftime("%H:%M:%S"), 
                    "–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ": "-", 
                    "–û–∂–∏–¥–∞–Ω–∏–µ": "0.0 –º–∏–Ω",  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                    "ReID": "‚úì" if enable_reid and analyze_clothing else "‚úó",
                    "ClothingFeatures": json.dumps({"analyzed": analyze_clothing})
                })
            
            for person_id in disappeared:
                for row in people_data:
                    if row["ID"] == int(person_id) and row["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] == "-":
                        row["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] = current_dt.strftime("%H:%M:%S")
                        try:
                            t1 = datetime.strptime(row["–ü–æ—è–≤–ª–µ–Ω–∏–µ"], "%H:%M:%S")
                            t2 = datetime.strptime(row["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"], "%H:%M:%S")
                            
                            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Ä–∞–∑–Ω–∏—Ü—ã –≤—Ä–µ–º–µ–Ω–∏
                            if t2 < t1:
                                # –ï—Å–ª–∏ –≤—Ä–µ–º—è —É—Ö–æ–¥–∞ –º–µ–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–∏—Ö–æ–¥–∞, –¥–æ–±–∞–≤–ª—è–µ–º 1 –¥–µ–Ω—å
                                t2 = t2 + timedelta(days=1)
                            
                            wait_seconds = (t2 - t1).total_seconds()
                            wait_minutes = wait_seconds / 60
                            
                            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ - –∏—Å–ø—Ä–∞–≤–ª—è–µ–º "–º–º" –Ω–∞ "–º–∏–Ω"
                            row["–û–∂–∏–¥–∞–Ω–∏–µ"] = f"{wait_minutes:.1f} –º–∏–Ω"
                        except Exception as e:
                            row["–û–∂–∏–¥–∞–Ω–∏–µ"] = "0.0 –º–∏–Ω"

            tracked_ids = current_ids

        # === –£–õ–£–ß–®–ï–ù–ù–ê–Ø –î–ï–¢–ï–ö–¶–ò–Ø –ü–û–ï–ó–î–ê ===
        train_detected = False
        best_train_confidence = 0
        best_train_info = ""

        if len(detections) > 0:
            # –ò—â–µ–º –±–æ–ª—å—à–∏–µ –æ–±—ä–µ–∫—Ç—ã —Å–ø—Ä–∞–≤–∞
            for i, (x1, y1, x2, y2) in enumerate(detections.xyxy):
                cls_id = int(detections.class_id[i])
                conf = detections.confidence[i]
                area = (x2 - x1) * (y2 - y1)
                
                # –§–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ –±–æ–ª—å—à–∏–µ –æ–±—ä–µ–∫—Ç—ã
                if area < original_w * original_h * 0.08:  # –º–∏–Ω–∏–º—É–º 8% –∫–∞–¥—Ä–∞
                    continue
                    
                in_train_zone, _ = is_in_train_zone(x1, y1, x2, y2, original_w, original_h)
                if not in_train_zone:
                    continue

                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: train > bus > truck > car (–µ—Å–ª–∏ –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π)
                if cls_id == 6:  # train
                    score = conf * 1.3
                elif cls_id == 5 or cls_id == 7:  # bus / truck
                    score = conf * 1.1
                elif cls_id == 2 and area > original_w * original_h * 0.2:  # –æ–≥—Ä–æ–º–Ω—ã–π car ‚Üí –≤–µ—Ä–æ—è—Ç–Ω–æ –ø–æ–µ–∑–¥
                    score = conf * 0.9
                else:
                    continue

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ü–≤–µ—Ç
                x1i, y1i, x2i, y2i = map(int, [x1, y1, x2, y2])
                x1i, y1i = max(0, x1i), max(0, y1i)
                x2i, y2i = min(original_w, x2i), min(original_h, y2i)
                roi = frame[y1i:y2i, x1i:x2i]
                
                if roi.size > 0:
                    gray_p, orange_p, red_p, combined_p = detect_train_colors(roi)
                    color_bonus = combined_p / 100 * 0.4
                    final_score = score + color_bonus

                    if final_score > best_train_confidence:
                        best_train_confidence = final_score
                        best_train_info = f"G:{gray_p:.0f}% O:{orange_p:.0f}% R:{red_p:.0f}% C:{combined_p:.0f}%"
                        train_detected = True

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ –ø–æ–µ–∑–¥–∞
        current_train_number = None
        if train_detected and train_number_ocr_enabled and reader is not None:
            # –û–±–ª–∞—Å—Ç—å –¥–ª—è –Ω–æ–º–µ—Ä–∞ –ø–æ–µ–∑–¥–∞ ‚Äî –æ–±—ã—á–Ω–æ –≤–≤–µ—Ä—Ö—É –≤–∞–≥–æ–Ω–∞ –∏–ª–∏ —Å–±–æ–∫—É
            number_roi_x = int(original_w * 0.6)
            number_roi_y = int(original_h * 0.3)
            number_roi_w = int(original_w * 0.35)
            number_roi_h = int(original_h * 0.15)
            
            crop = frame[number_roi_y:number_roi_y+number_roi_h, 
                         number_roi_x:number_roi_x+number_roi_w]
            
            if crop.size > 0:
                gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
                enhanced = cv2.convertScaleAbs(gray, alpha=2.0, beta=30)
                result = reader.readtext(enhanced, allowlist='0123456789–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•ABEKMHOPCTYX', detail=0)
                
                if result:
                    text = " ".join(result).upper()
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ —ç–ª–µ–∫—Ç—Ä–æ–ø–æ–µ–∑–¥–æ–≤
                    match = re.search(r'\b[–ê-–ØA-Z]{0,3}\d{3,4}[–ê-–ØA-Z]?\b', text)
                    if match:
                        current_train_number = match.group(0)
                    else:
                        current_train_number = result[0] if len(result) > 0 else None

            if current_train_number:
                train_number = current_train_number
                cv2.putText(frame, f"–ü–æ–µ–∑–¥: {train_number}", (10, 210), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
                st.sidebar.success(f"–ù–æ–º–µ—Ä –ø–æ–µ–∑–¥–∞: {train_number}")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏–π –ø–æ–µ–∑–¥–∞
        if train_detected and not train_present:
            train_arrival_time = current_dt.strftime("%H:%M:%S")
            train_present = True
            st.sidebar.success(f"üöÇ –ü–æ–µ–∑–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –≤ {train_arrival_time}")
            st.sidebar.info(f"–¶–≤–µ—Ç–∞: {best_train_info}")
            if train_number:
                st.sidebar.info(f"–ù–æ–º–µ—Ä –ø–æ–µ–∑–¥–∞: {train_number}")
        elif not train_detected and train_present:
            train_events.append({
                "–ü—Ä–∏–±—ã—Ç–∏–µ": train_arrival_time, 
                "–£–±—ã—Ç–∏–µ": current_dt.strftime("%H:%M:%S"),
                "–ù–æ–º–µ—Ä": train_number
            })
            train_present = False
            train_number = None
            st.sidebar.info(f"–ü–æ–µ–∑–¥ —É–µ—Ö–∞–ª –≤ {current_dt.strftime('%H:%M:%S')}")

        # === –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –õ–Æ–î–ï–ô –í–û–ó–õ–ï –ü–û–ï–ó–î–ê ===
        people_near_train = 0
        near_train_ids = []

        if train_detected:
            train_left = train_zone_x
            buffer = int(original_w * 0.08)  # ~150px –ø—Ä–∏ FullHD
            
            for i, (x1, y1, x2, y2) in enumerate(detections.xyxy):
                if detections.class_id[i] != 0:  # –Ω–µ —á–µ–ª–æ–≤–µ–∫
                    continue
                person_center_x = (x1 + x2) / 2
                
                if person_center_x >= train_left - buffer:
                    people_near_train += 1
                    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º ID
                    tracker_id = int(detections.tracker_id[i]) if detections.tracker_id is not None else 0
                    display_id = id_mapping.get(tracker_id, tracker_id) if enable_reid else tracker_id
                    near_train_ids.append(display_id)
                    
                    # –ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ–º —Ç–∞–∫–∏—Ö –ª—é–¥–µ–π –∫—Ä–∞—Å–Ω—ã–º
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 3)
                    cv2.putText(frame, "NEAR TRAIN", (int(x1), int(y1)-30), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º
            if people_near_train > max_people_near_train:
                max_people_near_train = people_near_train

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ –ø–æ–µ–∑–¥—É
        train_proximity_data.append({
            "time": current_dt.strftime("%H:%M:%S"), 
            "people_near_train": people_near_train
        })

        # –õ–∏–Ω–∏—è –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞
        line.trigger(detections=detections)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞ –Ω–∞ –∫–∞–¥—Ä–µ
        zone_x1, zone_y1, zone_x2, zone_y2 = is_in_train_zone(0, 0, 0, 0, original_w, original_h)[1]
        cv2.rectangle(frame, (zone_x1, zone_y1), (zone_x2, zone_y2), (0, 255, 255), 2)
        cv2.putText(frame, "TRAIN ZONE", (zone_x1, zone_y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        frame = box_annotator.annotate(scene=frame, detections=detections)
        frame = line_annotator.annotate(frame, line)

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ ID —Å —É—á–µ—Ç–æ–º ReID –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ–¥–µ–∂–¥–µ
        if detections.tracker_id is not None:
            for i, (x1, y1, x2, y2) in enumerate(detections.xyxy):
                class_id = detections.class_id[i]
                tracker_id = int(detections.tracker_id[i]) if detections.tracker_id is not None else 0
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                if class_id == 0 and enable_reid and analyze_clothing:  # –ß–µ–ª–æ–≤–µ–∫ —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º ReID
                    display_id = id_mapping.get(tracker_id, tracker_id)
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏
                    match_info = ""
                    if tracker_id in reid_matches:
                        matched_id = reid_matches[tracker_id]
                        match_info = f" (Matched: {matched_id})"
                    
                    id_text = f"Person {display_id}{match_info}"
                    color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π –¥–ª—è –ª—é–¥–µ–π —Å ReID
                    
                    # –†–∏—Å—É–µ–º bounding box —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –æ–¥–µ–∂–¥–µ
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    
                elif class_id == 0:  # –ß–µ–ª–æ–≤–µ–∫ –±–µ–∑ ReID
                    display_id = tracker_id
                    id_text = f"Person {display_id}"
                    color = (255, 255, 255)  # –ë–µ–ª—ã–π –¥–ª—è –ª—é–¥–µ–π –±–µ–∑ ReID
                elif class_id == 6:  # –ü–æ–µ–∑–¥
                    class_names = {0: "Person", 2: "Car", 3: "Motorcycle", 5: "Bus", 6: "Train", 7: "Truck"}
                    class_name = class_names.get(class_id, "Unknown")
                    id_text = f"{class_name} {tracker_id}"
                    color = (0, 255, 255)  # –ñ–µ–ª—Ç—ã–π –¥–ª—è –ø–æ–µ–∑–¥–æ–≤
                else:
                    class_names = {0: "Person", 2: "Car", 3: "Motorcycle", 5: "Bus", 6: "Train", 7: "Truck"}
                    class_name = class_names.get(class_id, "Unknown")
                    id_text = f"{class_name} {tracker_id}"
                    color = (255, 255, 255)  # –ë–µ–ª—ã–π –¥–ª—è –¥—Ä—É–≥–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                
                cv2.putText(frame, id_text, 
                           (int(x1), int(y1) - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 
                           0.5, color, 2)

        # –ù–∞–¥–ø–∏—Å—å –≤—Ä–µ–º–µ–Ω–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        cv2.putText(frame, f"Time: {timestamp_str}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"People: {people_count}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"Train: {'Yes' if train_present else 'No'}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"ReID: {'ON' if enable_reid else 'OFF'}", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"Clothing Analysis: {'ON' if analyze_clothing else 'OFF'}", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        if train_detected:
            cv2.putText(frame, f"Train Colors: {best_train_info}", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        if train_number:
            cv2.putText(frame, f"–ü–æ–µ–∑–¥: {train_number}", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        
        # –í—ã–≤–æ–¥–∏–º –Ω–∞ —ç–∫—Ä–∞–Ω –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª—é–¥—è—Ö –≤–æ–∑–ª–µ –ø–æ–µ–∑–¥–∞
        cv2.putText(frame, f"–í–æ–∑–ª–µ –ø–æ–µ–∑–¥–∞: {people_near_train}", (10, 240), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        stframe.image(frame, channels="BGR")
        progress.progress(min(frame_idx / frame_count, 1.0))
        frame_idx += 1
        processed_frames += 1

    cap.release()

    # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è
    stay_statistics = calculate_stay_statistics(people_data, occupancy)
    
    # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è
    total_waiting_time = calculate_total_waiting_time(people_data)
    waiting_distribution = analyze_waiting_distribution(people_data)
    total_people = len(people_data)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    waiting_stats = {
        'total_waiting_minutes': total_waiting_time,
        'average_waiting_minutes': total_waiting_time / total_people if total_people > 0 else 0,
        'less_1_min': waiting_distribution["–º–µ–Ω–µ–µ_1_–º–∏–Ω"],
        'between_1_5_min': waiting_distribution["1_5_–º–∏–Ω"],
        'between_5_15_min': waiting_distribution["5_15_–º–∏–Ω"],
        'more_15_min': waiting_distribution["–±–æ–ª–µ–µ_15_–º–∏–Ω"]
    }

    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö ===
    if db_enabled:
        try:
            with get_db_connection() as conn:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
                video_info = {
                    'filename': uploaded_file.name,
                    'frame_count': frame_count,
                    'processed_frames': processed_frames,
                    'duration_seconds': duration,
                    'resolution': f"{original_w}x{original_h}",
                    'fps': fps
                }
                
                video_id = save_video_info(conn, video_info)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
                save_people_data(conn, video_id, people_data)
                save_train_events(conn, video_id, train_events)
                save_occupancy(conn, video_id, occupancy)
                save_color_analysis(conn, video_id, color_analysis_data)
                save_line_statistics(conn, video_id, line.in_count, line.out_count)
                save_stay_statistics(conn, video_id, stay_statistics)
                save_waiting_statistics(conn, video_id, waiting_stats)
                save_train_proximity(conn, video_id, train_proximity_data)
                save_processing_settings(conn, video_id, processing_settings)
                
                conn.commit()
                
                st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (ID: {video_id})")
                
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö: {e}")

    # === –î–∞—à–±–æ—Ä–¥ ===
    st.success(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_frames} –∫–∞–¥—Ä–æ–≤ –∏–∑ {frame_count}")

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("üìä –õ—é–¥–∏ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ")
        if people_data:
            df_people = pd.DataFrame(people_data)
            # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å –±–∏–Ω–∞—Ä–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –æ–¥–µ–∂–¥—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            display_columns = [col for col in df_people.columns if col != "ClothingFeatures"]
            st.dataframe(df_people[display_columns])
            csv_people = df_people.to_csv(index=False).encode()
            st.download_button("–°–∫–∞—á–∞—Ç—å CSV –ª—é–¥–µ–π", csv_people, "people.csv")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ReID
            if enable_reid and reid_storage and analyze_clothing:
                st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ReID —Å –∞–Ω–∞–ª–∏–∑–æ–º –æ–¥–µ–∂–¥—ã")
                reid_count = len(reid_storage.known_features) if reid_storage else 0
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª—é–¥–µ–π (ReID)", reid_count)
                st.metric("–£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏", clothing_detail_level)

    with col2:
        st.subheader("üöÇ –ü–æ–µ–∑–¥–∞")
        if train_events:
            df_train = pd.DataFrame(train_events)
            st.dataframe(df_train)
            csv_train = df_train.to_csv(index=False).encode()
            st.download_button("–°–∫–∞—á–∞—Ç—å CSV –ø–æ–µ–∑–¥–æ–≤", csv_train, "trains.csv")
        else:
            st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–µ–∑–¥–∞—Ö")

    # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è
    st.subheader("‚è±Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("–û–±—â–µ–µ –≤—Ä–µ–º—è –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è", f"{stay_statistics['total_stay_minutes']:.1f} –º–∏–Ω")
        st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø—Ä–µ–±—ã–≤–∞–Ω–∏—è", f"{stay_statistics['average_stay_minutes']:.1f} –º–∏–Ω")
    
    with col2:
        st.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è", f"{stay_statistics['max_stay_minutes']:.1f} –º–∏–Ω")
        st.metric("–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è", f"{stay_statistics['min_stay_minutes']:.1f} –º–∏–Ω")
    
    with col3:
        st.metric("–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è", f"{stay_statistics['median_stay_minutes']:.1f} –º–∏–Ω")
        st.metric("–í—Å–µ–≥–æ –ª—é–¥–µ–π", stay_statistics['total_people'])

    # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –°—É–º–º–∞—Ä–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è
    st.subheader("üìä –°—É–º–º–∞—Ä–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è", f"{total_waiting_time:.1f} –º–∏–Ω")
        st.metric("–í—Å–µ–≥–æ –ª—é–¥–µ–π", total_people)

    with col2:
        if total_people > 0:
            avg_waiting = total_waiting_time / total_people
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è", f"{avg_waiting:.1f} –º–∏–Ω")
        else:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è", "0.0 –º–∏–Ω")

    with col3:
        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è
        max_waiting = 0.0
        for person in people_data:
            waiting_str = person.get("–û–∂–∏–¥–∞–Ω–∏–µ", "0.0 –º–∏–Ω")
            try:
                if "–º–∏–Ω" in waiting_str:
                    minutes = float(waiting_str.replace(" –º–∏–Ω", "").strip())
                    if minutes > max_waiting:
                        max_waiting = minutes
            except:
                continue
        st.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ", f"{max_waiting:.1f} –º–∏–Ω")

    # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ª—é–¥–µ–π –≤–æ–∑–ª–µ –ø–æ–µ–∑–¥–∞
    st.subheader("üöâ –õ—é–¥–∏ –≤–æ–∑–ª–µ –ø–æ–µ–∑–¥–∞")
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("–ú–∞–∫—Å–∏–º—É–º –ª—é–¥–µ–π –≤–æ–∑–ª–µ –ø–æ–µ–∑–¥–∞", max_people_near_train)
        
    with col2:
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π –Ω–æ–º–µ—Ä –ø–æ–µ–∑–¥–∞
        last_train_number = None
        for event in reversed(train_events):
            if event.get("–ù–æ–º–µ—Ä"):
                last_train_number = event["–ù–æ–º–µ—Ä"]
                break
                
        if last_train_number:
            st.success(f"–ü–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π –ø–æ–µ–∑–¥: {last_train_number}")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è
    st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è")

    if total_people > 0:
        distribution_data = {
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": ["< 1 –º–∏–Ω", "1-5 –º–∏–Ω", "5-15 –º–∏–Ω", "> 15 –º–∏–Ω"],
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—é–¥–µ–π": [
                waiting_distribution["–º–µ–Ω–µ–µ_1_–º–∏–Ω"],
                waiting_distribution["1_5_–º–∏–Ω"],
                waiting_distribution["5_15_–º–∏–Ω"],
                waiting_distribution["–±–æ–ª–µ–µ_15_–º–∏–Ω"]
            ]
        }
        
        df_distribution = pd.DataFrame(distribution_data)
        st.bar_chart(df_distribution.set_index("–ö–∞—Ç–µ–≥–æ—Ä–∏—è"))
        
        # –¢–∞–±–ª–∏—Ü–∞ —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π
        st.write("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        st.dataframe(df_distribution)
    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ü–≤–µ—Ç–æ–≤
    if color_analysis_data:
        st.subheader("üé® –ê–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤ –ø–æ–µ–∑–¥–∞")
        df_colors = pd.DataFrame(color_analysis_data)
        st.line_chart(df_colors[['gray', 'orange', 'red', 'combined']])

    st.subheader("üìà –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
    if occupancy:
        df_occ = pd.DataFrame(occupancy)
        st.line_chart(df_occ.set_index("time"))
    else:
        st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏")

    st.subheader("–í—Ö–æ–¥/–í—ã—Ö–æ–¥")
    st.write(f"–í–æ—à–ª–æ: {line.in_count}‚ÄÉ–í—ã—à–ª–æ: {line.out_count}")

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –∫–Ω–æ–ø–∫–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å—É–º–º–∞—Ä–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    if st.button("üì• –≠–∫—Å–ø–æ—Ä—Ç —Å—É–º–º–∞—Ä–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–∂–∏–¥–∞–Ω–∏—è"):
        summary_data = {
            "–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è (–º–∏–Ω)": total_waiting_time,
            "–í—Å–µ–≥–æ –ª—é–¥–µ–π": total_people,
            "–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è (–º–∏–Ω)": total_waiting_time / total_people if total_people > 0 else 0,
            "–ú–µ–Ω–µ–µ 1 –º–∏–Ω": waiting_distribution["–º–µ–Ω–µ–µ_1_–º–∏–Ω"],
            "1-5 –º–∏–Ω": waiting_distribution["1_5_–º–∏–Ω"],
            "5-15 –º–∏–Ω": waiting_distribution["5_15_–º–∏–Ω"],
            "–ë–æ–ª–µ–µ 15 –º–∏–Ω": waiting_distribution["–±–æ–ª–µ–µ_15_–º–∏–Ω"],
            "–ú–∞–∫—Å–∏–º—É–º –ª—é–¥–µ–π –≤–æ–∑–ª–µ –ø–æ–µ–∑–¥–∞": max_people_near_train,
            "–ü–æ—Å–ª–µ–¥–Ω–∏–π –Ω–æ–º–µ—Ä –ø–æ–µ–∑–¥–∞": last_train_number if last_train_number else "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω"
        }
        
        df_summary = pd.DataFrame([summary_data])
        csv_summary = df_summary.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å —Å—É–º–º–∞—Ä–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (CSV)",
            data=csv_summary,
            file_name="platform_analysis_summary.csv",
            mime="text/csv"
        )

# --- –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã ---
if db_enabled and os.path.exists(db_path):
    st.sidebar.header("–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î")
    
    if st.sidebar.button("–ü–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∞–Ω–∞–ª–∏–∑–æ–≤"):
        with get_db_connection() as conn:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ
            videos = conn.execute('''
                SELECT id, filename, processed_date, frame_count, processed_frames 
                FROM videos 
                ORDER BY processed_date DESC
            ''').fetchall()
            
            if videos:
                st.subheader("üìã –ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤ –≤–∏–¥–µ–æ")
                for video in videos:
                    with st.expander(f"{video['filename']} - {video['processed_date']}"):
                        st.write(f"ID: {video['id']}")
                        st.write(f"–ö–∞–¥—Ä–æ–≤: {video['frame_count']} (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {video['processed_frames']})")
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ª—é–¥—è–º
                        people_stats = conn.execute(
                            'SELECT COUNT(*) as total_people FROM people WHERE video_id = ?', 
                            (video['id'],)
                        ).fetchone()
                        st.write(f"–í—Å–µ–≥–æ –ª—é–¥–µ–π: {people_stats['total_people']}")
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–µ–∑–¥–∞–º
                        train_stats = conn.execute(
                            'SELECT COUNT(*) as total_trains FROM train_events WHERE video_id = ?', 
                            (video['id'],)
                        ).fetchone()
                        st.write(f"–°–æ–±—ã—Ç–∏–π –ø–æ–µ–∑–¥–æ–≤: {train_stats['total_trains']}")
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è
                        waiting_stats = conn.execute(
                            'SELECT total_waiting_minutes, average_waiting_minutes FROM waiting_statistics WHERE video_id = ?', 
                            (video['id'],)
                        ).fetchone()
                        if waiting_stats:
                            st.write(f"–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è: {waiting_stats['total_waiting_minutes']:.1f} –º–∏–Ω")
                            st.write(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è: {waiting_stats['average_waiting_minutes']:.1f} –º–∏–Ω")
                        
                        if st.button(f"–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤–∏–¥–µ–æ ID {video['id']}", key=f"load_{video['id']}"):
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ –≤–∏–¥–µ–æ
                            people_data_db = conn.execute(
                                'SELECT person_id, appearance_time, disappearance_time, waiting_minutes, reid_enabled FROM people WHERE video_id = ?',
                                (video['id'],)
                            ).fetchall()
                            
                            train_events_db = conn.execute(
                                'SELECT arrival_time, departure_time, duration_seconds, train_number FROM train_events WHERE video_id = ?',
                                (video['id'],)
                            ).fetchall()
                            
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                            if people_data_db:
                                st.subheader("–õ—é–¥–∏ –∏–∑ –ë–î")
                                df_people_db = pd.DataFrame(people_data_db)
                                st.dataframe(df_people_db)
                            
                            if train_events_db:
                                st.subheader("–ü–æ–µ–∑–¥–∞ –∏–∑ –ë–î")
                                df_train_db = pd.DataFrame(train_events_db)
                                st.dataframe(df_train_db)
            else:
                st.info("–í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π")