import streamlit as st
import cv2
import easyocr
import pandas as pd
from ultralytics import YOLO
from supervision import LineZone, BoxAnnotator, LineZoneAnnotator, Detections
from supervision.geometry.core import Point
from datetime import datetime, timedelta
import tempfile
import numpy as np
from collections import OrderedDict
import os

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
st.title("üöâ –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ —Å –∂–µ–ª–µ–∑–Ω–æ–¥–æ—Ä–æ–∂–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã")
st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")

confidence = st.sidebar.slider("Confidence", 0.0, 1.0, 0.4)
line_y = st.sidebar.slider("–ü–æ–∑–∏—Ü–∏—è –ª–∏–Ω–∏–∏", 0, 1080, 600)
skip_frames = st.sidebar.slider("–ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –∫–∞–¥—Ä–æ–≤", 1, 10, 2)
resize_factor = st.sidebar.slider("–£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è", 0.3, 1.0, 0.6)
disable_ocr = st.sidebar.checkbox("–û—Ç–∫–ª—é—á–∏—Ç—å OCR (—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏)", value=False)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–ª–∞—Å—Ç–∏ OCR
ocr_x = st.sidebar.slider("X-–ø–æ–∑–∏—Ü–∏—è OCR", 0, 1000, 10)
ocr_y = st.sidebar.slider("Y-–ø–æ–∑–∏—Ü–∏—è OCR", 0, 1000, 10)
ocr_width = st.sidebar.slider("–®–∏—Ä–∏–Ω–∞ OCR", 100, 800, 300)
ocr_height = st.sidebar.slider("–í—ã—Å–æ—Ç–∞ OCR", 20, 200, 50)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–æ–Ω—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–µ–∑–¥–∞
st.sidebar.subheader("–ó–æ–Ω–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–µ–∑–¥–∞")
train_zone_x = st.sidebar.slider("–ù–∞—á–∞–ª–æ –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞ (X)", 0, 1000, 500)
train_zone_width = st.sidebar.slider("–®–∏—Ä–∏–Ω–∞ –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞", 100, 1000, 500)
train_zone_y = st.sidebar.slider("–ù–∞—á–∞–ª–æ –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞ (Y)", 0, 800, 200)
train_zone_height = st.sidebar.slider("–í—ã—Å–æ—Ç–∞ –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞", 100, 1000, 400)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ü–≤–µ—Ç–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–µ–∑–¥–∞
st.sidebar.subheader("–¶–≤–µ—Ç–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ–µ–∑–¥–∞")
gray_lower = st.sidebar.slider("–°–µ—Ä—ã–π –Ω–∏–∂–Ω–∏–π –ø–æ—Ä–æ–≥", 0, 255, 50)
gray_upper = st.sidebar.slider("–°–µ—Ä—ã–π –≤–µ—Ä—Ö–Ω–∏–π –ø–æ—Ä–æ–≥", 0, 255, 200)
orange_lower_h = st.sidebar.slider("–û—Ä–∞–Ω–∂–µ–≤—ã–π H –Ω–∏–∂–Ω–∏–π", 0, 180, 5)
orange_upper_h = st.sidebar.slider("–û—Ä–∞–Ω–∂–µ–≤—ã–π H –≤–µ—Ä—Ö–Ω–∏–π", 0, 180, 15)
red_lower_h1 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H1 –Ω–∏–∂–Ω–∏–π", 0, 180, 0)
red_upper_h1 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H1 –≤–µ—Ä—Ö–Ω–∏–π", 0, 180, 10)
red_lower_h2 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H2 –Ω–∏–∂–Ω–∏–π", 0, 180, 170)
red_upper_h2 = st.sidebar.slider("–ö—Ä–∞—Å–Ω—ã–π H2 –≤–µ—Ä—Ö–Ω–∏–π", 0, 180, 180)

# ‚úÖ –£–ü–†–û–©–ï–ù–ù–´–ô ReID –Ω–∞ –æ—Å–Ω–æ–≤–µ OpenCV
st.sidebar.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ ReID")
reid_threshold = st.sidebar.slider("–ü–æ—Ä–æ–≥ ReID —Å—Ö–æ–¥—Å—Ç–≤–∞", 0.1, 1.0, 0.6)
enable_reid = st.sidebar.checkbox("–í–∫–ª—é—á–∏—Ç—å ReID", value=True)

# –ú–æ–¥–µ–ª—å
model = YOLO("yolov8n.pt")

# OCR —Ä–∏–¥–µ—Ä
reader = None
if not disable_ocr:
    try:
        reader = easyocr.Reader(['en'], gpu=False)
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å OCR: {e}")
        reader = None

# –ê–Ω–Ω–æ—Ç–∞—Ç–æ—Ä—ã
box_annotator = BoxAnnotator()
line_annotator = LineZoneAnnotator()
line = LineZone(start=Point(0, line_y), end=Point(9999, line_y))

# –•—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–∞–Ω–Ω—ã—Ö
people_data = []
train_events = []
occupancy = []

# ‚úÖ –£–ü–†–û–©–ï–ù–ù–´–ô ReID –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º –∏ ORB features
class SimpleReIDStorage:
    def __init__(self, similarity_threshold=0.6):
        self.similarity_threshold = similarity_threshold
        self.known_descriptors = OrderedDict()  # ID -> ORB descriptors
        self.known_histograms = OrderedDict()   # ID -> —Ü–≤–µ—Ç–æ–≤—ã–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        self.orb = cv2.ORB_create()
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        
    def extract_features(self, image, bbox):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞"""
        try:
            # –í—ã—Ä–µ–∑–∞–µ–º –æ–±–ª–∞—Å—Ç—å —á–µ–ª–æ–≤–µ–∫–∞
            x1, y1, x2, y2 = [int(coord) for coord in bbox]
            person_crop = image[y1:y2, x1:x2]
            
            if person_crop.size == 0:
                return None, None
                
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            lab = cv2.cvtColor(person_crop, cv2.COLOR_BGR2LAB)
            lab[:,:,0] = cv2.createCLAHE(clipLimit=2.0).apply(lab[:,:,0])
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ORB –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã
            gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)
            keypoints, descriptors = self.orb.detectAndCompute(gray, None)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—ã–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
            hsv = cv2.cvtColor(enhanced, cv2.COLOR_BGR2HSV)
            hist_h = cv2.calcHist([hsv], [0], None, [8], [0, 180])
            hist_s = cv2.calcHist([hsv], [1], None, [8], [0, 256])
            hist_v = cv2.calcHist([hsv], [2], None, [8], [0, 256])
            
            hist_h = cv2.normalize(hist_h, hist_h).flatten()
            hist_s = cv2.normalize(hist_s, hist_s).flatten()
            hist_v = cv2.normalize(hist_v, hist_v).flatten()
            histogram = np.concatenate([hist_h, hist_s, hist_v])
            
            return descriptors, histogram
        except Exception as e:
            return None, None
    
    def calculate_similarity(self, desc1, hist1, desc2, hist2):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–±–æ—Ä–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        similarity = 0.0
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã (70% –≤–µ—Å–∞)
        if hist1 is not None and hist2 is not None:
            hist_sim = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            similarity += hist_sim * 0.7
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º ORB –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã (30% –≤–µ—Å–∞)
        if desc1 is not None and desc2 is not None and len(desc1) > 0 and len(desc2) > 0:
            try:
                matches = self.bf.match(desc1, desc2)
                if len(matches) > 0:
                    orb_sim = len(matches) / min(len(desc1), len(desc2))
                    similarity += min(orb_sim, 1.0) * 0.3
            except:
                pass
        
        return similarity
    
    def find_best_match(self, new_descriptors, new_histogram):
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        if not self.known_descriptors:
            return None, 0.0
            
        best_match_id = None
        best_similarity = 0.0
        
        for person_id in self.known_descriptors:
            stored_desc, stored_hist = self.known_descriptors[person_id], self.known_histograms[person_id]
            similarity = self.calculate_similarity(new_descriptors, new_histogram, stored_desc, stored_hist)
            
            if similarity > best_similarity and similarity > self.similarity_threshold:
                best_similarity = similarity
                best_match_id = person_id
                
        return best_match_id, best_similarity
    
    def add_person(self, person_id, descriptors, histogram):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        self.known_descriptors[person_id] = descriptors
        self.known_histograms[person_id] = histogram
    
    def update_person(self, person_id, descriptors, histogram):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞"""
        if person_id in self.known_descriptors:
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–µ)
            old_desc = self.known_descriptors[person_id]
            if descriptors is not None and len(descriptors) > len(old_desc):
                self.known_descriptors[person_id] = descriptors
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É (—Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ)
            old_hist = self.known_histograms[person_id]
            alpha = 0.7
            new_hist = alpha * old_hist + (1 - alpha) * histogram
            self.known_histograms[person_id] = new_hist
        else:
            self.add_person(person_id, descriptors, histogram)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ ReID
reid_storage = SimpleReIDStorage(similarity_threshold=reid_threshold) if enable_reid else None

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ü–≤–µ—Ç–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
def detect_train_colors(roi):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ü–≤–µ—Ç–æ–≤ –ø–æ–µ–∑–¥–∞ –≤ –æ–±–ª–∞—Å—Ç–∏"""
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    
    gray_mask = cv2.inRange(roi, (gray_lower, gray_lower, gray_lower), (gray_upper, gray_upper, gray_upper))
    
    lower_orange = np.array([orange_lower_h, 100, 100])
    upper_orange = np.array([orange_upper_h, 255, 255])
    orange_mask = cv2.inRange(hsv, lower_orange, upper_orange)
    
    lower_red1 = np.array([red_lower_h1, 100, 100])
    upper_red1 = np.array([red_upper_h1, 255, 255])
    lower_red2 = np.array([red_lower_h2, 100, 100])
    upper_red2 = np.array([red_upper_h2, 255, 255])
    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    red_mask = cv2.bitwise_or(red_mask1, red_mask2)
    
    combined_mask = cv2.bitwise_or(gray_mask, orange_mask)
    combined_mask = cv2.bitwise_or(combined_mask, red_mask)
    
    total_pixels = roi.shape[0] * roi.shape[1]
    if total_pixels == 0:
        return 0, 0, 0, 0
    
    gray_percent = np.sum(gray_mask > 0) / total_pixels * 100
    orange_percent = np.sum(orange_mask > 0) / total_pixels * 100
    red_percent = np.sum(red_mask > 0) / total_pixels * 100
    combined_percent = np.sum(combined_mask > 0) / total_pixels * 100
    
    return gray_percent, orange_percent, red_percent, combined_percent

def is_in_train_zone(x1, y1, x2, y2, frame_width, frame_height):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –æ–±—ä–µ–∫—Ç –≤ –∑–æ–Ω–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–µ–∑–¥–∞"""
    zone_x1 = train_zone_x
    zone_x2 = min(frame_width, train_zone_x + train_zone_width)
    zone_y1 = train_zone_y
    zone_y2 = min(frame_height, train_zone_y + train_zone_height)
    
    center_x = (x1 + x2) / 2
    center_y = (y1 + y2) / 2
    
    in_zone = (zone_x1 <= center_x <= zone_x2) and (zone_y1 <= center_y <= zone_y2)
    
    overlap_x = max(0, min(x2, zone_x2) - max(x1, zone_x1))
    overlap_y = max(0, min(y2, zone_y2) - max(y1, zone_y1))
    overlap_area = overlap_x * overlap_y
    object_area = (x2 - x1) * (y2 - y1)
    
    if object_area > 0:
        overlap_ratio = overlap_area / object_area
    else:
        overlap_ratio = 0
    
    return in_zone or overlap_ratio > 0.3, (zone_x1, zone_y1, zone_x2, zone_y2)

uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏ –≤–∏–¥–µ–æ —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã", type=["mp4", "avi", "mov"])

if uploaded_file:
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    video_path = tfile.name

    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    original_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    process_w = int(original_w * resize_factor)
    process_h = int(original_h * resize_factor)

    stframe = st.empty()
    progress = st.progress(0)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # –î–ª—è –ø–æ–µ–∑–¥–∞
    train_present = False
    train_arrival_time = None
    tracked_ids = set()
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ —Å—Ç–∞—Ä—ã—Ö ID –∫ –Ω–æ–≤—ã–º —á–µ—Ä–µ–∑ ReID
    id_mapping = {}  # –Ω–æ–≤—ã–π_tracker_id -> —Å—Ç–∞—Ä—ã–π_person_id
    next_person_id = 1
    
    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ü–≤–µ—Ç–æ–≤
    color_analysis_data = []

    frame_idx = 0
    processed_frames = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –∫–∞–¥—Ä—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        if frame_idx % skip_frames != 0:
            frame_idx += 1
            continue

        # –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if resize_factor < 1.0:
            process_frame = cv2.resize(frame, (process_w, process_h))
        else:
            process_frame = frame

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
        timestamp_str = "00:00:00"
        current_dt = datetime.now()
        
        if not disable_ocr and reader is not None:
            try:
                y1 = max(0, min(ocr_y, frame.shape[0] - ocr_height))
                y2 = min(frame.shape[0], y1 + ocr_height)
                x1 = max(0, min(ocr_x, frame.shape[1] - ocr_width))
                x2 = min(frame.shape[1], x1 + ocr_width)
                
                crop = frame[y1:y2, x1:x2]
                gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
                enhanced = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)
                blurred = cv2.GaussianBlur(enhanced, (3, 3), 0)
                
                result = reader.readtext(blurred, detail=0, paragraph=True)
                
                if result:
                    timestamp_str = result[0]
                    time_formats = ["%H:%M:%S", "%H:%M", "%I:%M:%S %p", "%I:%M %p"]
                    
                    for fmt in time_formats:
                        try:
                            current_time = datetime.strptime(timestamp_str, fmt).time()
                            current_dt = datetime.combine(datetime.today(), current_time)
                            break
                        except:
                            continue
                            
            except Exception as e:
                st.sidebar.warning(f"–û—à–∏–±–∫–∞ OCR: {e}")

        # –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
        results = model.track(process_frame, persist=True, conf=confidence, 
                            classes=[0, 2, 3, 5, 6, 7], tracker="bytetrack.yaml", verbose=False)[0]
        
        # –°–æ–∑–¥–∞–µ–º Detections –æ–±—ä–µ–∫—Ç
        if results.boxes.id is not None:
            boxes = results.boxes.xyxy.cpu().numpy()
            confidence_scores = results.boxes.conf.cpu().numpy()
            class_ids = results.boxes.cls.cpu().numpy().astype(int)
            tracker_ids = results.boxes.id.cpu().numpy().astype(int)
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
            if resize_factor < 1.0:
                boxes = boxes / resize_factor
            
            detections = Detections(
                xyxy=boxes,
                confidence=confidence_scores,
                class_id=class_ids,
                tracker_id=tracker_ids
            )
            
            tracks = tracker_ids
        else:
            detections = Detections(
                xyxy=np.empty((0, 4)),
                confidence=np.array([]),
                class_id=np.array([], dtype=int)
            )
            tracks = None

        # –£–ü–†–û–©–ï–ù–ù–´–ô ReID –ª–æ–≥–∏–∫–∞ –¥–ª—è –ª—é–¥–µ–π
        current_people_tracks = []
        reid_matches = {}
        
        if enable_reid and reid_storage is not None and tracks is not None:
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª—é–¥–µ–π
            people_indices = np.where(detections.class_id == 0)[0]
            
            for idx in people_indices:
                tracker_id = int(tracks[idx])
                bbox = detections.xyxy[idx]
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
                descriptors, histogram = reid_storage.extract_features(frame, bbox)
                
                if descriptors is not None or histogram is not None:
                    # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ª—é–¥—è—Ö
                    matched_id, similarity = reid_storage.find_best_match(descriptors, histogram)
                    
                    if matched_id is not None and similarity > reid_threshold:
                        # –ù–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π ID
                        reid_matches[tracker_id] = matched_id
                        reid_storage.update_person(matched_id, descriptors, histogram)
                        current_people_tracks.append(matched_id)
                    else:
                        # –ù–æ–≤—ã–π —á–µ–ª–æ–≤–µ–∫ –∏–ª–∏ –Ω–µ—Ç —Ö–æ—Ä–æ—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                        if tracker_id not in id_mapping:
                            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π ID
                            new_person_id = next_person_id
                            next_person_id += 1
                            id_mapping[tracker_id] = new_person_id
                            reid_storage.add_person(new_person_id, descriptors, histogram)
                            current_people_tracks.append(new_person_id)
                        else:
                            # –£–∂–µ –µ—Å—Ç—å –º–∞–ø–ø–∏–Ω–≥
                            current_people_tracks.append(id_mapping[tracker_id])
                else:
                    # –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º tracker_id
                    if tracker_id not in id_mapping:
                        new_person_id = next_person_id
                        next_person_id += 1
                        id_mapping[tracker_id] = new_person_id
                    current_people_tracks.append(id_mapping[tracker_id])
        
        # –¢–µ–∫—É—â–µ–µ –∫–æ–ª-–≤–æ –ª—é–¥–µ–π
        people_count = np.sum(detections.class_id == 0) if len(detections) > 0 else 0
        occupancy.append({"time": current_dt.strftime("%H:%M:%S"), "people": people_count})

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ª—é–¥–µ–π —Å —É—á–µ—Ç–æ–º ReID
        if tracks is not None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º ReID ID –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã, –∏–Ω–∞—á–µ tracker_id
            if enable_reid and current_people_tracks:
                current_ids = set(current_people_tracks)
            else:
                current_ids = set(tracks[detections.class_id == 0])
            
            appeared = current_ids - tracked_ids
            disappeared = tracked_ids - current_ids

            for person_id in appeared:
                people_data.append({
                    "ID": int(person_id), 
                    "–ü–æ—è–≤–ª–µ–Ω–∏–µ": current_dt.strftime("%H:%M:%S"), 
                    "–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ": "-", 
                    "–û–∂–∏–¥–∞–Ω–∏–µ": "-",
                    "ReID": "‚úì" if enable_reid else "‚úó"
                })
            
            for person_id in disappeared:
                for row in people_data:
                    if row["ID"] == int(person_id) and row["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] == "-":
                        row["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"] = current_dt.strftime("%H:%M:%S")
                        try:
                            t1 = datetime.strptime(row["–ü–æ—è–≤–ª–µ–Ω–∏–µ"], "%H:%M:%S")
                            t2 = datetime.strptime(row["–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ"], "%H:%M:%S")
                            wait = (t2 - t1).total_seconds() / 60
                            row["–û–∂–∏–¥–∞–Ω–∏–µ"] = f"{wait:.1f} –º–∏–Ω"
                        except:
                            row["–û–∂–∏–¥–∞–Ω–∏–µ"] = "0.0 –º–∏–Ω"

            tracked_ids = current_ids

        # –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–µ–∑–¥–æ–≤ –¢–û–õ–¨–ö–û –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∑–æ–Ω–µ
        train_detected = False
        best_train_confidence = 0
        best_train_info = ""
        
        if len(detections) > 0:
            potential_train_indices = np.where((detections.class_id == 6) |  # train
                                             ((detections.class_id == 5) & (detections.confidence > 0.6)) |  # bus
                                             ((detections.class_id == 7) & (detections.confidence > 0.6)))[0]  # truck
            
            for idx in potential_train_indices:
                x1, y1, x2, y2 = detections.xyxy[idx].astype(int)
                width = x2 - x1
                height = y2 - y1
                
                in_train_zone, zone_coords = is_in_train_zone(x1, y1, x2, y2, original_w, original_h)
                
                if not in_train_zone:
                    continue
                
                if width > original_w * 0.25 and height > original_h * 0.15:
                    x1_clip = max(0, x1)
                    y1_clip = max(0, y1)
                    x2_clip = min(original_w, x2)
                    y2_clip = min(original_h, y2)
                    
                    roi = frame[y1_clip:y2_clip, x1_clip:x2_clip]
                    
                    if roi.size > 0:
                        gray_percent, orange_percent, red_percent, combined_percent = detect_train_colors(roi)
                        
                        color_analysis_data.append({
                            "frame": frame_idx,
                            "gray": gray_percent,
                            "orange": orange_percent,
                            "red": red_percent,
                            "combined": combined_percent
                        })
                        
                        is_train_by_color = (
                            (gray_percent > 10) or
                            (orange_percent > 5) or
                            (red_percent > 5) or
                            (combined_percent > 15)
                        )
                        
                        detection_confidence = detections.confidence[idx]
                        combined_confidence = detection_confidence * 0.7 + (combined_percent / 100) * 0.3
                        
                        if is_train_by_color and combined_confidence > 0.5:
                            if combined_confidence > best_train_confidence:
                                best_train_confidence = combined_confidence
                                best_train_info = f"G:{gray_percent:.1f}% O:{orange_percent:.1f}% R:{red_percent:.1f}%"
                            train_detected = True

        if train_detected and not train_present:
            train_arrival_time = current_dt.strftime("%H:%M:%S")
            train_present = True
            st.sidebar.success(f"üöÇ –ü–æ–µ–∑–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –≤ {train_arrival_time}")
            st.sidebar.info(f"–¶–≤–µ—Ç–∞: {best_train_info}")
        elif not train_detected and train_present:
            train_events.append({
                "–ü—Ä–∏–±—ã—Ç–∏–µ": train_arrival_time, 
                "–£–±—ã—Ç–∏–µ": current_dt.strftime("%H:%M:%S")
            })
            train_present = False
            st.sidebar.info(f"–ü–æ–µ–∑–¥ —É–µ—Ö–∞–ª –≤ {current_dt.strftime('%H:%M:%S')}")

        # –õ–∏–Ω–∏—è –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞
        line.trigger(detections=detections)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–æ–Ω—ã –ø–æ–µ–∑–¥–∞ –Ω–∞ –∫–∞–¥—Ä–µ
        zone_x1, zone_y1, zone_x2, zone_y2 = is_in_train_zone(0, 0, 0, 0, original_w, original_h)[1]
        cv2.rectangle(frame, (zone_x1, zone_y1), (zone_x2, zone_y2), (0, 255, 255), 2)
        cv2.putText(frame, "TRAIN ZONE", (zone_x1, zone_y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        frame = box_annotator.annotate(scene=frame, detections=detections)
        frame = line_annotator.annotate(frame, line)

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ ID —Å —É—á–µ—Ç–æ–º ReID
        if detections.tracker_id is not None:
            for i, (x1, y1, x2, y2) in enumerate(detections.xyxy):
                class_id = detections.class_id[i]
                tracker_id = int(detections.tracker_id[i]) if detections.tracker_id is not None else 0
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                if class_id == 0 and enable_reid:  # –ß–µ–ª–æ–≤–µ–∫ —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º ReID
                    display_id = id_mapping.get(tracker_id, tracker_id)
                    id_text = f"Person {display_id}"
                    color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π –¥–ª—è –ª—é–¥–µ–π —Å ReID
                elif class_id == 0:  # –ß–µ–ª–æ–≤–µ–∫ –±–µ–∑ ReID
                    display_id = tracker_id
                    id_text = f"Person {display_id}"
                    color = (255, 255, 255)  # –ë–µ–ª—ã–π –¥–ª—è –ª—é–¥–µ–π –±–µ–∑ ReID
                elif class_id == 6:  # –ü–æ–µ–∑–¥
                    class_names = {0: "Person", 2: "Car", 3: "Motorcycle", 5: "Bus", 6: "Train", 7: "Truck"}
                    class_name = class_names.get(class_id, "Unknown")
                    id_text = f"{class_name} {tracker_id}"
                    color = (0, 255, 255)  # –ñ–µ–ª—Ç—ã–π –¥–ª—è –ø–æ–µ–∑–¥–æ–≤
                else:
                    class_names = {0: "Person", 2: "Car", 3: "Motorcycle", 5: "Bus", 6: "Train", 7: "Truck"}
                    class_name = class_names.get(class_id, "Unknown")
                    id_text = f"{class_name} {tracker_id}"
                    color = (255, 255, 255)  # –ë–µ–ª—ã–π –¥–ª—è –¥—Ä—É–≥–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                
                cv2.putText(frame, id_text, 
                           (int(x1), int(y1) - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 
                           0.5, color, 2)

        # –ù–∞–¥–ø–∏—Å—å –≤—Ä–µ–º–µ–Ω–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        cv2.putText(frame, f"Time: {timestamp_str}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"People: {people_count}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"Train: {'Yes' if train_present else 'No'}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, f"ReID: {'ON' if enable_reid else 'OFF'}", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        if train_detected:
            cv2.putText(frame, f"Train Colors: {best_train_info}", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

        stframe.image(frame, channels="BGR")
        progress.progress(min(frame_idx / frame_count, 1.0))
        frame_idx += 1
        processed_frames += 1

    cap.release()

    # === –î–∞—à–±–æ—Ä–¥ ===
    st.success(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_frames} –∫–∞–¥—Ä–æ–≤ –∏–∑ {frame_count}")

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("üìä –õ—é–¥–∏ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ")
        if people_data:
            df_people = pd.DataFrame(people_data)
            st.dataframe(df_people)
            csv_people = df_people.to_csv(index=False).encode()
            st.download_button("–°–∫–∞—á–∞—Ç—å CSV –ª—é–¥–µ–π", csv_people, "people.csv")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ReID
            if enable_reid and reid_storage:
                st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ReID")
                reid_count = len(reid_storage.known_descriptors) if reid_storage else 0
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª—é–¥–µ–π (ReID)", reid_count)
        else:
            st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ª—é–¥—è—Ö")

    with col2:
        st.subheader("üöÇ –ü–æ–µ–∑–¥–∞")
        if train_events:
            df_train = pd.DataFrame(train_events)
            st.dataframe(df_train)
            csv_train = df_train.to_csv(index=False).encode()
            st.download_button("–°–∫–∞—á–∞—Ç—å CSV –ø–æ–µ–∑–¥–æ–≤", csv_train, "trains.csv")
        else:
            st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–µ–∑–¥–∞—Ö")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ü–≤–µ—Ç–æ–≤
    if color_analysis_data:
        st.subheader("üé® –ê–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤ –ø–æ–µ–∑–¥–∞")
        df_colors = pd.DataFrame(color_analysis_data)
        st.line_chart(df_colors[['gray', 'orange', 'red', 'combined']])

    st.subheader("üìà –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
    if occupancy:
        df_occ = pd.DataFrame(occupancy)
        st.line_chart(df_occ.set_index("time"))
    else:
        st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏")

    if people_data:
        try:
            wait_times = [float(row["–û–∂–∏–¥–∞–Ω–∏–µ"].replace(" –º–∏–Ω", "")) for row in people_data if row["–û–∂–∏–¥–∞–Ω–∏–µ"] != "-"]
            if wait_times:
                avg_wait = sum(wait_times) / len(wait_times)
                st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ–µ–∑–¥–∞", f"{avg_wait:.1f} –º–∏–Ω")
        except:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ–µ–∑–¥–∞", "–ù/–î")

    st.subheader("–í—Ö–æ–¥/–í—ã—Ö–æ–¥")
    st.write(f"–í–æ—à–ª–æ: {line.in_count}‚ÄÉ–í—ã—à–ª–æ: {line.out_count}")
    ///—Ñ—ã–≤–∞